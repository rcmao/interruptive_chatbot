"""
ä¿®å¤ç‰ˆæœ¬çš„ç›‘æ§ç³»ç»Ÿ - æ›´æ•æ„Ÿçš„å†²çªæ£€æµ‹
"""

import asyncio
import aiohttp
import openai
import os
import time
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from collections import deque, defaultdict
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SignalResult:
    """ä¿¡å·æ£€æµ‹ç»“æœ"""
    signal_type: str
    value: float
    confidence: float
    processing_time: float
    timestamp: datetime

@dataclass
class RealTimeMetrics:
    """å®æ—¶æ€§èƒ½æŒ‡æ ‡"""
    total_processing_time: float = 0.0
    llm_processing_time: float = 0.0
    local_processing_time: float = 0.0
    signal_count: int = 0
    intervention_count: int = 0
    avg_response_time: float = 0.0

class LightweightConflictDetectorFixed:
    """ä¿®å¤ç‰ˆæœ¬çš„è½»é‡çº§å†²çªæ£€æµ‹å™¨ - æ›´æ•æ„Ÿ"""
    
    def __init__(self):
        self.emotion_keywords = {
            "anger": ["æ„¤æ€’", "ç”Ÿæ°”", "æ¼ç«", "æ„¤æ…¨", "angry", "mad", "furious"],
            "frustration": ["æŒ«æŠ˜", "æ²®ä¸§", "å¤±æœ›", "frustrated", "disappointed"],
            "disagreement": ["ä¸åŒæ„", "åå¯¹", "é”™è¯¯", "ä¸åˆç†", "disagree", "wrong", "incorrect", "unreasonable"],
            "negative": ["è’è°¬", "æ„šè ¢", "æ— ç†", "ridiculous", "stupid", "unreasonable", "å®Œå…¨", "ç»å¯¹"],
            "personal": ["ä½ ä»ä¸", "ä½ æ€»æ˜¯", "ä½ é”™äº†", "you never", "you always", "you're wrong"],
            "strong": ["å®Œå…¨", "ç»å¯¹", "å¤ª", "éå¸¸", "extremely", "completely", "absolutely"]
        }
        
    def quick_score(self, content: str, context: List[str] = None) -> float:
        """å¿«é€Ÿå†²çªåˆ†æ•°è®¡ç®— - æ›´æ•æ„Ÿçš„ç‰ˆæœ¬"""
        if not content:
            return 0.0
        
        score = 0.0
        content_lower = content.lower()
        
        # å…³é”®è¯æ£€æµ‹ - å¢åŠ æƒé‡
        for category, keywords in self.emotion_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    # ä¸åŒç±»å‹å…³é”®è¯ç»™ä¸åŒæƒé‡
                    if category == "personal":
                        score += 0.3  # äººèº«æ”»å‡»æƒé‡æœ€é«˜
                    elif category == "negative":
                        score += 0.25  # è´Ÿé¢è¯æ±‡æƒé‡å¾ˆé«˜
                    elif category == "strong":
                        score += 0.2   # å¼ºè°ƒè¯æ±‡
                    elif category == "disagreement":
                        score += 0.15  # åˆ†æ­§è¯æ±‡
                    else:
                        score += 0.1
        
        # è¯­æ°”å¼ºåº¦æ£€æµ‹ - å¢åŠ æƒé‡
        if "!" in content:
            score += 0.15  # æ„Ÿå¹å·æƒé‡å¢åŠ 
        if "ï¼Ÿ" in content:
            score += 0.08
        if content.isupper():  # å…¨å¤§å†™
            score += 0.2
        
        # ç‰¹æ®Šæ¨¡å¼æ£€æµ‹
        if "ä¸è¡Œ" in content or "ä¸å¯ä»¥" in content:
            score += 0.2
        if "ä»ä¸" in content or "æ€»æ˜¯" in content:
            score += 0.25
        if "never" in content_lower or "always" in content_lower:
            score += 0.25
        
        # ä¸Šä¸‹æ–‡åˆ†æ - å¢åŠ æƒé‡
        if context:
            context_str = " ".join(context).lower()
            if any(word in context_str for word in ["å†²çª", "äº‰è®º", "åˆ†æ­§", "conflict", "argue"]):
                score += 0.15
        
        return min(score, 1.0)

class AsyncLLMProcessorFixed:
    """ä¿®å¤ç‰ˆæœ¬çš„å¼‚æ­¥LLMå¤„ç†å™¨"""
    
    def __init__(self, api_key: str, api_base: str):
        self.api_key = api_key
        self.api_base = api_base
        self.client = None
        
    async def initialize(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        try:
            self.client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.api_base
            )
            logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None
    
    async def predictive_score(self, messages: List[str], priority: str = "normal") -> float:
        """é¢„æµ‹æ€§å†²çªè¯„åˆ†"""
        if not self.client:
            logger.warning("âš ï¸  APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æœ¬åœ°è¯„åˆ†")
            return self._local_fallback_score(messages)
        
        try:
            # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯çš„å¼‚æ­¥åŒ…è£…
            score = await asyncio.get_event_loop().run_in_executor(
                None, self._compute_llm_score_sync, messages
            )
            return score
        except Exception as e:
            logger.warning(f"âš ï¸  LLMè¯„åˆ†å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°è¯„åˆ†: {e}")
            return self._local_fallback_score(messages)
    
    def _compute_llm_score_sync(self, messages: List[str]) -> float:
        """åŒæ­¥è®¡ç®—LLMå†²çªåˆ†æ•°"""
        prompt = f"""
å¿«é€Ÿåˆ†æå¯¹è¯å†²çªç¨‹åº¦(0-1åˆ†ï¼Œ0.3ä»¥ä¸Šè¡¨ç¤ºéœ€è¦å…³æ³¨):

æœ€è¿‘å¯¹è¯:
{chr(10).join(messages[-3:])}

è¯„åˆ†æ ‡å‡†:
- 0-0.2: æ­£å¸¸è®¨è®º
- 0.3-0.5: è½»å¾®åˆ†æ­§ï¼Œéœ€è¦å…³æ³¨
- 0.6-0.8: æ˜æ˜¾å†²çªï¼Œå»ºè®®å¹²é¢„
- 0.9-1.0: æ¿€çƒˆå†²çªï¼Œç«‹å³å¹²é¢„

åªè¿”å›æ•°å­—åˆ†æ•°ï¼Œä¾‹å¦‚: 0.7
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=10,
                timeout=3  # å‡å°‘è¶…æ—¶æ—¶é—´
            )
            
            score_text = response.choices[0].message.content.strip()
            
            import re
            match = re.search(r'0\.\d+|1\.0|0|1', score_text)
            return float(match.group()) if match else 0.5
            
        except Exception as e:
            logger.warning(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return 0.5
    
    def _local_fallback_score(self, messages: List[str]) -> float:
        """æœ¬åœ°å›é€€è¯„åˆ†ç®—æ³• - æ›´æ•æ„Ÿ"""
        if not messages:
            return 0.0
        
        # æ‰©å±•çš„å†²çªå…³é”®è¯
        conflict_keywords = [
            "é”™è¯¯", "è’è°¬", "æ„šè ¢", "ä¸è¡Œ", "åå¯¹", "ä¸åŒæ„", "ä¸åˆç†",
            "wrong", "ridiculous", "stupid", "disagree", "never", "always",
            "å®Œå…¨", "ç»å¯¹", "å¤ª", "ä»ä¸", "æ€»æ˜¯"
        ]
        
        score = 0.0
        recent_messages = messages[-3:]  # æœ€è¿‘3æ¡æ¶ˆæ¯
        
        for message in recent_messages:
            content = message.lower()
            keyword_count = sum(1 for keyword in conflict_keywords if keyword in content)
            score += keyword_count * 0.15  # å¢åŠ æƒé‡
        
        # æ¶ˆæ¯é•¿åº¦å’Œè¯­æ°”
        if recent_messages:
            last_message = recent_messages[-1]
            if "!" in last_message:
                score += 0.15
            if "ï¼Ÿ" in last_message:
                score += 0.08
            if len(last_message) < 10:  # çŸ­æ¶ˆæ¯å¯èƒ½æ›´æƒ…ç»ªåŒ–
                score += 0.1
        
        return min(score, 1.0)

class IntelligentTriggerLogicFixed:
    """ä¿®å¤ç‰ˆæœ¬çš„æ™ºèƒ½è§¦å‘é€»è¾‘ - æ›´æ•æ„Ÿçš„é˜ˆå€¼"""
    
    def __init__(self):
        # å¤§å¹…é™ä½é˜ˆå€¼ï¼Œæé«˜æ•æ„Ÿæ€§
        self.base_threshold = 0.2  # ä»0.35è¿›ä¸€æ­¥é™ä½åˆ°0.2
        self.recent_interventions = deque(maxlen=10)
        
    def should_intervene(self, signal_results: Dict[str, SignalResult]) -> Tuple[bool, float, str]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å¹²é¢„ - æ›´æ•æ„Ÿçš„é€»è¾‘"""
        
        # å®‰å…¨åœ°è·å–å„ç§ä¿¡å·åˆ†æ•°
        llm_score = signal_results.get("llm").value if signal_results.get("llm") else 0.0
        lightweight_score = signal_results.get("lightweight").value if signal_results.get("lightweight") else 0.0
        emotion_score = signal_results.get("emotion").value if signal_results.get("emotion") else 0.0
        turn_taking_score = signal_results.get("turn_taking").value if signal_results.get("turn_taking") else 0.0
        
        # å¤šä¿¡å·èåˆç®—æ³• - è°ƒæ•´æƒé‡
        final_score = (
            lightweight_score * 0.5 +     # è½»é‡çº§æ£€æµ‹æƒé‡æé«˜åˆ°50%
            emotion_score * 0.25 +         # æƒ…ç»ªæ£€æµ‹æƒé‡25%
            llm_score * 0.15 +             # LLMè¯„åˆ†æƒé‡15%
            turn_taking_score * 0.1        # å‘è¨€æƒæ£€æµ‹æƒé‡10%
        )
        
        # åŠ¨æ€é˜ˆå€¼è°ƒæ•´
        adjusted_threshold = self.base_threshold
        
        # å¦‚æœæœ€è¿‘æœ‰å¹²é¢„ï¼Œç•¥å¾®æé«˜é˜ˆå€¼é¿å…è¿‡åº¦å¹²é¢„
        recent_interventions = len([
            t for t in self.recent_interventions 
            if (datetime.now() - t).seconds < 180  # å‡å°‘åˆ°3åˆ†é’Ÿå†…
        ])
        
        if recent_interventions > 0:
            adjusted_threshold += 0.05 * recent_interventions  # å‡å°‘è°ƒæ•´å¹…åº¦
        
        # ç‰¹æ®Šæƒ…å†µè§¦å‘å™¨ - é™ä½é˜ˆå€¼
        high_emotion_trigger = (
            emotion_score > 0.3 and 
            (lightweight_score > 0.15 or turn_taking_score > 0.15)
        )
        
        # å¼ºçƒˆå†²çªå…³é”®è¯è§¦å‘ - é™ä½é˜ˆå€¼
        strong_conflict_trigger = lightweight_score > 0.25
        
        # LLMé«˜åˆ†è§¦å‘
        llm_high_trigger = llm_score > 0.4
        
        # å†³ç­–é€»è¾‘
        should_intervene = (
            final_score >= adjusted_threshold or 
            high_emotion_trigger or
            strong_conflict_trigger or
            llm_high_trigger
        )
        
        # è®°å½•å¹²é¢„
        if should_intervene:
            self.recent_interventions.append(datetime.now())
        
        # ç”ŸæˆåŸå› 
        reason = self._generate_reason(final_score, adjusted_threshold, signal_results, 
                                     high_emotion_trigger, strong_conflict_trigger, llm_high_trigger)
        
        return should_intervene, final_score, reason
    
    def _generate_reason(self, score: float, threshold: float, signals: Dict, 
                        high_emotion: bool, strong_conflict: bool, llm_high: bool) -> str:
        """ç”Ÿæˆå¹²é¢„åŸå› """
        if llm_high:
            llm_score = signals.get("llm").value if signals.get("llm") else 0.0
            return f"LLMæ£€æµ‹åˆ°é«˜å†²çª(åˆ†æ•°:{llm_score:.2f})"
        
        if strong_conflict:
            lightweight_score = signals.get("lightweight").value if signals.get("lightweight") else 0.0
            return f"æ£€æµ‹åˆ°å¼ºçƒˆå†²çªå…³é”®è¯(åˆ†æ•°:{lightweight_score:.2f})"
        
        if high_emotion:
            emotion_score = signals.get("emotion").value if signals.get("emotion") else 0.0
            return f"æ£€æµ‹åˆ°é«˜æƒ…ç»ªåŒ–è¡¨è¾¾(åˆ†æ•°:{emotion_score:.2f})"
        
        if score >= threshold:
            return f"ç»¼åˆå†²çªåˆ†æ•°{score:.2f}è¶…è¿‡é˜ˆå€¼{threshold:.2f}"
        
        return "å¤šä¿¡å·ç»¼åˆè§¦å‘"

class ParallelSignalProcessorFixed:
    """ä¿®å¤ç‰ˆæœ¬çš„å¹¶è¡Œä¿¡å·å¤„ç†å™¨"""
    
    def __init__(self, api_key: str, api_base: str):
        self.lightweight_detector = LightweightConflictDetectorFixed()
        self.llm_processor = AsyncLLMProcessorFixed(api_key, api_base)
        self.message_history = deque(maxlen=10)
        self.metrics = RealTimeMetrics()
        
    async def initialize(self):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        await self.llm_processor.initialize()
        
    async def process_signals_parallel(self, message_data) -> Dict[str, SignalResult]:
        """å¹¶è¡Œå¤„ç†æ‰€æœ‰ä¿¡å·"""
        start_time = time.time()
        
        # æ›´æ–°å†å²è®°å½•
        self.message_history.append(message_data)
        context = [f"{msg.author_name}: {msg.content}" for msg in list(self.message_history)]
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = [
            self._process_lightweight_score(message_data.content, context),
            self._process_emotion_detection(message_data.content),
            self._process_turn_taking(list(self.message_history)),
        ]
        
        # å¹¶è¡Œæ‰§è¡Œæœ¬åœ°ä¿¡å·æ£€æµ‹
        local_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¼‚æ­¥å¯åŠ¨LLMå¤„ç†
        llm_task = asyncio.create_task(
            self._process_llm_score(context, message_data)
        )
        
        # ç»„è£…ç»“æœ
        results = {}
        signal_names = ["lightweight", "emotion", "turn_taking"]
        
        for i, result in enumerate(local_results):
            if not isinstance(result, Exception):
                results[signal_names[i]] = result
        
        # ç­‰å¾…LLMç»“æœ
        try:
            llm_result = await asyncio.wait_for(llm_task, timeout=1.5)  # è¿›ä¸€æ­¥å‡å°‘è¶…æ—¶æ—¶é—´
            results["llm"] = llm_result
        except asyncio.TimeoutError:
            logger.warning("LLMå¤„ç†è¶…æ—¶ï¼Œä½¿ç”¨æœ¬åœ°è¯„åˆ†")
            # ä½¿ç”¨æœ¬åœ°è¯„åˆ†ä½œä¸ºLLMå›é€€
            local_score = self.lightweight_detector.quick_score(message_data.content, context)
            results["llm"] = SignalResult("llm", local_score * 0.8, 0.5, 0.0, datetime.now())
        except Exception as e:
            logger.warning(f"LLMå¤„ç†å¤±è´¥: {e}")
            local_score = self.lightweight_detector.quick_score(message_data.content, context)
            results["llm"] = SignalResult("llm", local_score * 0.8, 0.5, 0.0, datetime.now())
        
        # æ›´æ–°æŒ‡æ ‡
        self.metrics.signal_count += 1
        processing_time = time.time() - start_time
        self.metrics.total_processing_time = processing_time
        
        return results
    
    async def _process_lightweight_score(self, content: str, context: List[str]) -> SignalResult:
        """å¤„ç†è½»é‡çº§è¯„åˆ†"""
        start_time = time.time()
        score = self.lightweight_detector.quick_score(content, context)
        processing_time = time.time() - start_time
        
        return SignalResult("lightweight", score, 0.9, processing_time, datetime.now())
    
    async def _process_emotion_detection(self, content: str) -> SignalResult:
        """å¤„ç†æƒ…ç»ªæ£€æµ‹ - æ›´æ•æ„Ÿ"""
        start_time = time.time()
        
        # æ‰©å±•çš„æƒ…ç»ªå…³é”®è¯æ£€æµ‹
        emotion_keywords = [
            "æ„¤æ€’", "ç”Ÿæ°”", "æ¼ç«", "æ²®ä¸§", "å¤±æœ›", "æ„¤æ…¨",
            "angry", "mad", "frustrated", "disappointed", "furious"
        ]
        score = 0.0
        
        content_lower = content.lower()
        for keyword in emotion_keywords:
            if keyword in content_lower:
                score += 0.25  # å¢åŠ æƒé‡
        
        # è¯­æ°”æ£€æµ‹ - å¢åŠ æƒé‡
        if "!" in content:
            score += 0.15
        if "ï¼Ÿ" in content and any(word in content_lower for word in ["ä¸ºä»€ä¹ˆ", "æ€ä¹ˆ", "why", "how"]):
            score += 0.1
        if content.isupper():
            score += 0.2
        
        # ç‰¹æ®Šæ¨¡å¼
        if any(pattern in content for pattern in ["ä»ä¸", "æ€»æ˜¯", "never", "always"]):
            score += 0.2
        
        processing_time = time.time() - start_time
        return SignalResult("emotion", min(score, 1.0), 0.8, processing_time, datetime.now())
    
    async def _process_turn_taking(self, messages: List) -> SignalResult:
        """å¤„ç†å‘è¨€æƒæ£€æµ‹"""
        start_time = time.time()
        
        if len(messages) < 3:
            return SignalResult("turn_taking", 0.0, 0.7, time.time() - start_time, datetime.now())
        
        # æ£€æµ‹é‡å¤å‘è¨€
        recent_speakers = [msg.author_id for msg in messages[-3:]]
        unique_speakers = len(set(recent_speakers))
        
        # å¦‚æœåŒä¸€äººè¿ç»­å‘è¨€ï¼Œåˆ†æ•°å¢åŠ 
        score = 0.0
        if unique_speakers == 1:
            score = 0.4  # å¢åŠ åˆ†æ•°
        elif unique_speakers == 2:
            score = 0.15
        
        processing_time = time.time() - start_time
        return SignalResult("turn_taking", score, 0.7, processing_time, datetime.now())
    
    async def _process_llm_score(self, context: List[str], message_data) -> SignalResult:
        """å¤„ç†LLMè¯„åˆ†"""
        start_time = time.time()
        
        score = await self.llm_processor.predictive_score(context)
        
        processing_time = time.time() - start_time
        return SignalResult("llm", score, 0.9, processing_time, datetime.now())

class OptimizedConflictMonitorFixed:
    """ä¿®å¤ç‰ˆæœ¬çš„ä¼˜åŒ–å†²çªç›‘æ§ä¸»ç±»"""
    
    def __init__(self, api_key: str, api_base: str):
        self.signal_processor = ParallelSignalProcessorFixed(api_key, api_base)
        self.trigger_logic = IntelligentTriggerLogicFixed()
        self.performance_monitor = RealTimeMetrics()
        
    async def initialize(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        await self.signal_processor.initialize()
        logger.info("ğŸš€ ä¼˜åŒ–çš„å†²çªç›‘æ§ç³»ç»Ÿå·²åˆå§‹åŒ–")
    
    async def process_message(self, message_data) -> Tuple[bool, float, str, Dict]:
        """å¤„ç†æ¶ˆæ¯å¹¶è¿”å›å¹²é¢„å†³ç­–"""
        start_time = time.time()
        
        try:
            # å¹¶è¡Œå¤„ç†æ‰€æœ‰ä¿¡å·
            signal_results = await self.signal_processor.process_signals_parallel(message_data)
            
            # æ™ºèƒ½å†³ç­–
            should_intervene, final_score, reason = self.trigger_logic.should_intervene(signal_results)
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            processing_time = time.time() - start_time
            self.performance_monitor.total_processing_time = processing_time
            self.performance_monitor.avg_response_time = processing_time
            
            if should_intervene:
                self.performance_monitor.intervention_count += 1
            
            # æ˜¾ç¤ºè¯¦ç»†ä¿¡å·åˆ†æ•°
            signal_details = {
                name: f"{result.value:.2f}" for name, result in signal_results.items()
            }
            
            logger.info(f"ğŸ“Š å¤„ç†å®Œæˆ: {processing_time:.3f}s, åˆ†æ•°: {final_score:.2f}, å¹²é¢„: {should_intervene}")
            logger.info(f"ğŸ” ä¿¡å·è¯¦æƒ…: {signal_details}")
            
            return should_intervene, final_score, reason, signal_results
            
        except Exception as e:
            logger.error(f"âŒ æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤å€¼
            return False, 0.0, f"å¤„ç†å¤±è´¥: {e}", {}
    
    def get_performance_metrics(self) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        return {
            "avg_response_time": self.performance_monitor.avg_response_time,
            "total_signals_processed": self.signal_processor.metrics.signal_count,
            "intervention_rate": (
                self.performance_monitor.intervention_count / 
                max(1, self.signal_processor.metrics.signal_count)
            ),
            "total_interventions": self.performance_monitor.intervention_count
        } 