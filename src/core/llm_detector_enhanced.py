"""
å¢å¼ºç‰ˆGPT-4å†²çªæ£€æµ‹ç³»ç»Ÿ - æ”¯æŒå•äººå’Œå¤šäººå¯¹è¯åˆ†æ
"""

import asyncio
import os
import logging
from datetime import datetime
from collections import deque
from enum import Enum
from typing import List, Dict, Optional, Set
from dataclasses import dataclass
import json
import aiohttp
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

class TKIStrategy(Enum):
    """TKIå¹²é¢„ç­–ç•¥"""
    COLLABORATING = "åä½œ"
    ACCOMMODATING = "è¿å°±"
    COMPETING = "ç«äº‰"
    AVOIDING = "å›é¿"
    COMPROMISING = "å¦¥å"

class ConflictLevel(Enum):
    """å†²çªç­‰çº§"""
    NONE = "æ— å†²çª"
    MILD = "è½»å¾®åˆ†æ­§"
    MODERATE = "ä¸­ç­‰å†²çª"
    HIGH = "ä¸¥é‡å†²çª"
    CRITICAL = "å±é™©å†²çª"

class AnalysisMode(Enum):
    """åˆ†ææ¨¡å¼"""
    SINGLE_SPEAKER = "å•äººæ¨¡å¼"
    MULTI_SPEAKER = "å¤šäººå¯¹è¯"
    WAITING = "ç­‰å¾…æ›´å¤šå‚ä¸è€…"

@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡"""
    speaker: str
    content: str
    timestamp: datetime
    turn_number: int

@dataclass
class LLMAnalysisResult:
    """LLMåˆ†æç»“æœ"""
    conflict_score: float
    conflict_level: ConflictLevel
    conflict_type: str
    emotional_tone: str
    escalation_risk: float
    recommended_strategy: TKIStrategy
    intervention_message: str
    analysis_reasoning: str
    should_intervene: bool
    analysis_mode: AnalysisMode

class SmartGPT4Analyzer:
    """æ™ºèƒ½GPT-4åˆ†æå™¨ - æ”¯æŒå•äººå’Œå¤šäººæ¨¡å¼"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.conversation_history = deque(maxlen=15)
        self.unique_speakers: Set[str] = set()
        
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
    
    async def analyze_conversation(self, new_speaker: str, new_message: str) -> LLMAnalysisResult:
        """æ™ºèƒ½åˆ†æå¯¹è¯"""
        
        logger.info(f"æ¥æ”¶åˆ°æ¶ˆæ¯: {new_speaker}: {new_message}")
        
        # æ·»åŠ æ–°æ¶ˆæ¯åˆ°å†å²
        turn = ConversationTurn(
            speaker=new_speaker,
            content=new_message,
            timestamp=datetime.now(),
            turn_number=len(self.conversation_history) + 1
        )
        self.conversation_history.append(turn)
        self.unique_speakers.add(new_speaker)
        
        # æ™ºèƒ½å†³å®šåˆ†ææ¨¡å¼
        analysis_mode = self._determine_analysis_mode()
        
        if analysis_mode == AnalysisMode.WAITING:
            return LLMAnalysisResult(
                conflict_score=0.0,
                conflict_level=ConflictLevel.NONE,
                conflict_type="ç­‰å¾…æ›´å¤šå‚ä¸è€…",
                emotional_tone="ä¸­æ€§",
                escalation_risk=0.0,
                recommended_strategy=TKIStrategy.COLLABORATING,
                intervention_message="",
                analysis_reasoning="å•äººå¯¹è¯ï¼Œç­‰å¾…å…¶ä»–å‚ä¸è€…åŠ å…¥æˆ–æ›´å¤šæ¶ˆæ¯",
                should_intervene=False,
                analysis_mode=analysis_mode
            )
        else:
            return await self._call_gpt4_analysis(analysis_mode)
    
    def _determine_analysis_mode(self) -> AnalysisMode:
        """æ™ºèƒ½ç¡®å®šåˆ†ææ¨¡å¼"""
        
        # å¦‚æœåªæœ‰1ä¸ªäººä¸”æ¶ˆæ¯å°‘äº3æ¡ï¼Œç­‰å¾…
        if len(self.unique_speakers) == 1 and len(self.conversation_history) < 3:
            return AnalysisMode.WAITING
        
        # å¦‚æœæœ‰å¤šä¸ªå‚ä¸è€…ï¼Œç«‹å³åˆ†æ
        if len(self.unique_speakers) > 1:
            return AnalysisMode.MULTI_SPEAKER
        
        # å¦‚æœå•äººä½†æ¶ˆæ¯è¾ƒå¤šï¼Œä¹Ÿè¿›è¡Œåˆ†æï¼ˆå¯èƒ½æ˜¯è‡ªæˆ‘å†²çªæˆ–å‹åŠ›è¡¨è¾¾ï¼‰
        if len(self.unique_speakers) == 1 and len(self.conversation_history) >= 3:
            return AnalysisMode.SINGLE_SPEAKER
        
        return AnalysisMode.WAITING
    
    async def _call_gpt4_analysis(self, mode: AnalysisMode) -> LLMAnalysisResult:
        """è°ƒç”¨GPT-4è¿›è¡Œåˆ†æ"""
        
        conversation_text = self._format_conversation_for_llm()
        logger.info(f"åˆ†ææ¨¡å¼: {mode.value}, å¯¹è¯: {conversation_text}")
        
        # æ ¹æ®æ¨¡å¼è°ƒæ•´ç³»ç»Ÿæç¤º
        if mode == AnalysisMode.SINGLE_SPEAKER:
            system_prompt = """ä½ æ˜¯å†²çªæ£€æµ‹ä¸“å®¶ã€‚å½“å‰æ˜¯å•äººå¯¹è¯æ¨¡å¼ï¼Œé‡ç‚¹åˆ†æï¼š
1. ä¸ªäººå‹åŠ›å’ŒæŒ«è´¥æ„Ÿè¡¨è¾¾
2. æ—¶é—´ç´§è¿«æ„Ÿå’Œç„¦è™‘
3. å¯¹ä»–äººçš„ä¸æ»¡æˆ–æŠ±æ€¨
4. é‡å¤æ€§çš„æ‹…å¿§æˆ–é—®é¢˜
5. æƒ…ç»ªå‡çº§çš„è¿¹è±¡

å•äººå¯¹è¯ä¸­çš„å†²çªä¿¡å·åŒ…æ‹¬ï¼š
- åå¤æåŠåŒä¸€é—®é¢˜
- è¡¨è¾¾æ—¶é—´å‹åŠ›æˆ–deadlineç„¦è™‘
- å¯¹ä»–äººè¡Œä¸ºçš„æŠ±æ€¨
- æƒ…ç»ªåŒ–çš„è¡¨è¾¾
- å¯»æ±‚ç¡®è®¤æˆ–æ”¯æŒçš„è¿«åˆ‡éœ€æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼å›å¤ï¼š
{
    "conflict_score": æ•°å€¼0-1,
    "conflict_level": "æ— å†²çª/è½»å¾®åˆ†æ­§/ä¸­ç­‰å†²çª/ä¸¥é‡å†²çª/å±é™©å†²çª",
    "conflict_type": "å†²çªç±»å‹æè¿°",
    "emotional_tone": "æƒ…ç»ªæè¿°",
    "escalation_risk": æ•°å€¼0-1,
    "recommended_strategy": "åä½œ/è¿å°±/ç«äº‰/å›é¿/å¦¥å",
    "should_intervene": trueæˆ–false,
    "intervention_message": "å¹²é¢„æ¶ˆæ¯",
    "analysis_reasoning": "åˆ†æåŸå› "
}"""
        else:
            system_prompt = """ä½ æ˜¯å†²çªæ£€æµ‹ä¸“å®¶ã€‚å½“å‰æ˜¯å¤šäººå¯¹è¯æ¨¡å¼ï¼Œé‡ç‚¹åˆ†æï¼š
1. å‚ä¸è€…ä¹‹é—´çš„ç›´æ¥å†²çª
2. é—´æ¥çš„ä¸æ»¡å’Œæš—ç¤º
3. è´£ä»»æ¨å¸å’Œç›¸äº’æŒ‡è´£
4. æƒ…ç»ªåœ¨å‚ä¸è€…é—´çš„ä¼ æ’­
5. ç¾¤ä½“åŠ¨åŠ›å­¦é—®é¢˜

å¤šäººå¯¹è¯ä¸­çš„å†²çªä¿¡å·åŒ…æ‹¬ï¼š
- ä¸åŒè§‚ç‚¹çš„ç¢°æ’
- ç›¸äº’æŒ‡è´£æˆ–è´£å¤‡
- é˜²å¾¡æ€§å›åº”
- æƒåŠ›æ–—äº‰
- æ²Ÿé€šå¤±æ•ˆ

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼å›å¤ï¼š
{
    "conflict_score": æ•°å€¼0-1,
    "conflict_level": "æ— å†²çª/è½»å¾®åˆ†æ­§/ä¸­ç­‰å†²çª/ä¸¥é‡å†²çª/å±é™©å†²çª",
    "conflict_type": "å†²çªç±»å‹æè¿°",
    "emotional_tone": "æƒ…ç»ªæè¿°",
    "escalation_risk": æ•°å€¼0-1,
    "recommended_strategy": "åä½œ/è¿å°±/ç«äº‰/å›é¿/å¦¥å",
    "should_intervene": trueæˆ–false,
    "intervention_message": "å¹²é¢„æ¶ˆæ¯",
    "analysis_reasoning": "åˆ†æåŸå› "
}"""

        user_prompt = f"åˆ†æä»¥ä¸‹å¯¹è¯çš„å†²çªç¨‹åº¦ï¼ˆ{mode.value}ï¼‰ï¼š\n\n{conversation_text}"

        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-4',
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'temperature': 0.1,
                'max_tokens': 800
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f'{self.base_url}/chat/completions',
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"GPT-4 API error: {response.status} - {error_text}")
                        return self._create_fallback_result(f"APIé”™è¯¯: {response.status}", mode)
                    
                    result = await response.json()
                    
                    if 'choices' not in result or not result['choices']:
                        logger.error("GPT-4 API returned no choices")
                        return self._create_fallback_result("APIè¿”å›ä¸ºç©º", mode)
                    
                    gpt_response = result['choices'][0]['message']['content'].strip()
                    logger.info(f"GPT-4åŸå§‹å›å¤: {gpt_response}")
                    
                    return self._parse_gpt4_response(gpt_response, mode)
                    
        except Exception as e:
            logger.error(f"GPT-4 API call failed: {e}")
            return self._create_fallback_result(f"APIé”™è¯¯: {str(e)}", mode)
    
    def _format_conversation_for_llm(self) -> str:
        """æ ¼å¼åŒ–å¯¹è¯ä¾›LLMåˆ†æ"""
        conversation_lines = []
        
        for turn in self.conversation_history:
            conversation_lines.append(f"{turn.speaker}: {turn.content}")
        
        return "\n".join(conversation_lines)
    
    def _parse_gpt4_response(self, response: str, mode: AnalysisMode) -> LLMAnalysisResult:
        """è§£æGPT-4çš„JSONå“åº”"""
        try:
            # å¤šç§æ–¹å¼å°è¯•è§£æJSON
            data = None
            
            # å°è¯•ç›´æ¥è§£æ
            try:
                data = json.loads(response.strip())
            except json.JSONDecodeError:
                pass
            
            # å°è¯•æå–å¤§æ‹¬å·å†…å®¹
            if data is None:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    try:
                        data = json.loads(response[json_start:json_end])
                    except json.JSONDecodeError:
                        pass
            
            # å°è¯•æ¸…ç†markdown
            if data is None:
                import re
                cleaned = re.sub(r'```json\s*|\s*```', '', response).strip()
                try:
                    data = json.loads(cleaned)
                except json.JSONDecodeError:
                    pass
            
            if data is None:
                logger.error(f"æ— æ³•è§£æGPT-4å“åº”ä¸ºJSON: {response}")
                return self._create_fallback_result("JSONè§£æå¤±è´¥", mode)
            
            # æ˜ å°„æšä¸¾å€¼
            level_map = {
                "æ— å†²çª": ConflictLevel.NONE,
                "è½»å¾®åˆ†æ­§": ConflictLevel.MILD,
                "ä¸­ç­‰å†²çª": ConflictLevel.MODERATE,
                "ä¸¥é‡å†²çª": ConflictLevel.HIGH,
                "å±é™©å†²çª": ConflictLevel.CRITICAL
            }
            
            strategy_map = {
                "åä½œ": TKIStrategy.COLLABORATING,
                "è¿å°±": TKIStrategy.ACCOMMODATING,
                "ç«äº‰": TKIStrategy.COMPETING,
                "å›é¿": TKIStrategy.AVOIDING,
                "å¦¥å": TKIStrategy.COMPROMISING
            }
            
            return LLMAnalysisResult(
                conflict_score=float(data.get('conflict_score', 0.0)),
                conflict_level=level_map.get(data.get('conflict_level', 'æ— å†²çª'), ConflictLevel.NONE),
                conflict_type=data.get('conflict_type', 'æœªçŸ¥'),
                emotional_tone=data.get('emotional_tone', 'ä¸­æ€§'),
                escalation_risk=float(data.get('escalation_risk', 0.0)),
                recommended_strategy=strategy_map.get(data.get('recommended_strategy', 'åä½œ'), TKIStrategy.COLLABORATING),
                intervention_message=data.get('intervention_message', ''),
                analysis_reasoning=data.get('analysis_reasoning', ''),
                should_intervene=bool(data.get('should_intervene', False)),
                analysis_mode=mode
            )
            
        except Exception as e:
            logger.error(f"è§£æGPT-4å“åº”å¤±è´¥: {e}")
            return self._create_fallback_result(f"è§£æé”™è¯¯: {str(e)}", mode)
    
    def _create_fallback_result(self, error_reason: str, mode: AnalysisMode) -> LLMAnalysisResult:
        """åˆ›å»ºé™çº§ç»“æœ"""
        return LLMAnalysisResult(
            conflict_score=0.0,
            conflict_level=ConflictLevel.NONE,
            conflict_type="åˆ†æå¤±è´¥",
            emotional_tone="æœªçŸ¥",
            escalation_risk=0.0,
            recommended_strategy=TKIStrategy.COLLABORATING,
            intervention_message="",
            analysis_reasoning=f"GPT-4åˆ†æå¤±è´¥: {error_reason}",
            should_intervene=False,
            analysis_mode=mode
        )

# å…¨å±€åˆ†æå™¨
smart_analyzer = SmartGPT4Analyzer()
message_count = 0

def format_score_bar(score: float, width: int = 10) -> str:
    """æ ¼å¼åŒ–åˆ†æ•°æ¡å½¢å›¾"""
    filled = int(score * width)
    return "â–ˆ" * filled + "â–‘" * (width - filled)

def get_color_indicator(score: float) -> str:
    """è·å–é¢œè‰²æŒ‡ç¤ºå™¨"""
    if score >= 0.8:
        return "ğŸ”´"
    elif score >= 0.6:
        return "ğŸŸ "
    elif score >= 0.4:
        return "ğŸŸ¡"
    elif score >= 0.2:
        return "ğŸŸ¢"
    else:
        return "âšª"

def get_mode_icon(mode: AnalysisMode) -> str:
    """è·å–æ¨¡å¼å›¾æ ‡"""
    icons = {
        AnalysisMode.SINGLE_SPEAKER: "ğŸ‘¤",
        AnalysisMode.MULTI_SPEAKER: "ğŸ‘¥",
        AnalysisMode.WAITING: "â³"
    }
    return icons.get(mode, "â“")

def print_startup_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    start_time = datetime.now()
    banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                ğŸ¤– æ™ºèƒ½GPT-4å†²çªæ£€æµ‹æœºå™¨äºº - å•äºº/å¤šäººè‡ªé€‚åº” v3.0                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ å¯åŠ¨æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}                                                â•‘
â•‘ åˆ†æå¼•æ“: ğŸ§  GPT-4 (è‡ªé€‚åº”æ¨¡å¼)                                                    â•‘
â•‘ æ”¯æŒæ¨¡å¼: ğŸ‘¤å•äººå‹åŠ›æ£€æµ‹ | ğŸ‘¥å¤šäººå†²çªåˆ†æ | â³æ™ºèƒ½ç­‰å¾…                               â•‘
â•‘                                                                              â•‘
â•‘ å•äººæ¨¡å¼: å‹åŠ›è¡¨è¾¾ | æ—¶é—´ç„¦è™‘ | é‡å¤æ‹…å¿§ | æƒ…ç»ªå‡çº§                                   â•‘
â•‘ å¤šäººæ¨¡å¼: ç›´æ¥å†²çª | ç›¸äº’æŒ‡è´£ | é˜²å¾¡å›åº” | ç¾¤ä½“åŠ¨åŠ›                                   â•‘
â•‘ å›¾ä¾‹: ğŸš¨=å¹²é¢„ âœ…=æ­£å¸¸ ğŸ‘¤ğŸ‘¥â³=æ¨¡å¼ ğŸ”´ğŸŸ ğŸŸ¡ğŸŸ¢âšª=ç­‰çº§                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)

async def log_smart_analysis(message: str, author: str, result: LLMAnalysisResult, processing_time: float):
    """è®°å½•æ™ºèƒ½åˆ†æç»“æœ"""
    global message_count
    message_count += 1
    
    timestamp = datetime.now().strftime('%H:%M:%S')
    status = "ğŸš¨" if result.should_intervene else "âœ…"
    mode_icon = get_mode_icon(result.analysis_mode)
    
    message_preview = message[:40] + "..." if len(message) > 40 else message
    if not message.strip():
        message_preview = "[ç©ºæ¶ˆæ¯]"
    
    score_bar = format_score_bar(result.conflict_score)
    color_indicator = get_color_indicator(result.conflict_score)
    
    # æ˜¾ç¤ºå‚ä¸è€…ä¿¡æ¯
    speaker_count = len(smart_analyzer.unique_speakers)
    speakers_info = f"å‚ä¸è€…: {speaker_count}äºº ({', '.join(smart_analyzer.unique_speakers)})"
    
    print(f"""
{status} [{timestamp}] {author} (è½®æ¬¡#{message_count}) {mode_icon}
ğŸ“ {message_preview}
ğŸ‘¥ {speakers_info}
ğŸ“Š å†²çªåˆ†æ•°: {result.conflict_score:.2f} {score_bar} {color_indicator}
ğŸ” å†²çªç±»å‹: {result.conflict_type}
ğŸ˜Š æƒ…ç»ªè‰²è°ƒ: {result.emotional_tone}
ğŸ“ˆ å‡çº§é£é™©: {result.escalation_risk:.2f}
ğŸ¯ æ¨èç­–ç•¥: {result.recommended_strategy.value}
ğŸ§  åˆ†ææ¨¡å¼: {result.analysis_mode.value}
â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.1f}ms
ğŸ’­ GPT-4åˆ†æ: {result.analysis_reasoning}
""".strip())
    
    if result.should_intervene:
        print(f"ğŸ’¬ æ™ºèƒ½å¹²é¢„: {result.intervention_message}")
    
    print("â”€" * 70)

class SmartConflictBot:
    """æ™ºèƒ½å†²çªæ£€æµ‹æœºå™¨äºº"""
    
    def __init__(self):
        self.discord_client = None
        
    async def start(self, token: str):
        """å¯åŠ¨Discordæœºå™¨äºº"""
        import discord
        
        print_startup_banner()
        
        class DiscordBot(discord.Client):
            def __init__(self):
                super().__init__(intents=discord.Intents.default())
                
            async def on_ready(self):
                logger.info(f'ğŸš€ æœºå™¨äººå·²ç™»å½•ä¸º {self.user}')
                print(f"\nğŸŒŸ {self.user} å·²ä¸Šçº¿ï¼Œæ™ºèƒ½åˆ†æå¼€å§‹...")
                print("=" * 70)
                
            async def on_message(self, message):
                if message.author == self.user:
                    return
                
                message_content = message.content
                author_name = message.author.display_name
                
                logger.info(f"Discordæ¶ˆæ¯: {author_name}: {message_content}")
                
                start_processing = asyncio.get_event_loop().time()
                
                try:
                    result = await smart_analyzer.analyze_conversation(author_name, message_content)
                    processing_time = (asyncio.get_event_loop().time() - start_processing) * 1000
                    
                    await log_smart_analysis(message_content, author_name, result, processing_time)
                    
                    if result.should_intervene:
                        await message.channel.send(result.intervention_message)
                        
                except Exception as e:
                    logger.error(f"æ™ºèƒ½åˆ†æå¤±è´¥: {e}")
                    print(f"âŒ æ™ºèƒ½åˆ†æå¤±è´¥: {e}")
        
        self.discord_client = DiscordBot()
        await self.discord_client.start(token)

async def main():
    """ä¸»å‡½æ•°"""
    token = os.getenv('DISCORD_TOKEN')
    if not token:
        logger.error("DISCORD_TOKEN not found")
        return
    
    if not os.getenv('OPENAI_API_KEY'):
        logger.error("OPENAI_API_KEY not found")
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OPENAI_API_KEY")
        return
    
    bot = SmartConflictBot()
    
    try:
        logger.info("Starting Smart GPT-4 conflict intervention bot...")
        await bot.start(token)
    except KeyboardInterrupt:
        logger.info("Bot shutting down...")
        print(f"\nğŸ›‘ æœºå™¨äººå·²åœæ­¢ - å…±åˆ†æ {message_count} æ¡æ¶ˆæ¯")
    except Exception as e:
        logger.error(f"Startup failed: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 