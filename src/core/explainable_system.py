"""
å¯è§£é‡Šæ€§å¢å¼ºçš„å®æ—¶å†²çªå¹²é¢„ç³»ç»Ÿ
è§£å†³Thomasæ¨¡å‹ä¸LLMæ‰“åˆ†å†²çªé—®é¢˜
"""

import asyncio
from enum import Enum
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class ConflictEvidence(Enum):
    """å†²çªè¯æ®ç±»å‹"""
    KEYWORD_BASED = "keyword"           # å…³é”®è¯è¯æ®
    LINGUISTIC_PATTERN = "linguistic"   # è¯­è¨€æ¨¡å¼è¯æ®  
    EMOTIONAL_INDICATOR = "emotional"   # æƒ…ç»ªæŒ‡æ ‡è¯æ®
    BEHAVIORAL_SIGNAL = "behavioral"    # è¡Œä¸ºä¿¡å·è¯æ®
    CONTEXTUAL_TREND = "contextual"     # ä¸Šä¸‹æ–‡è¶‹åŠ¿è¯æ®
    LLM_SEMANTIC = "llm_semantic"       # LLMè¯­ä¹‰ç†è§£è¯æ®

class ConfidenceLevel(Enum):
    """ç½®ä¿¡åº¦ç­‰çº§"""
    HIGH = "high"       # >0.8
    MEDIUM = "medium"   # 0.5-0.8
    LOW = "low"         # 0.3-0.5
    UNCERTAIN = "uncertain"  # <0.3

@dataclass
class ConflictSignal:
    """å•ä¸ªå†²çªä¿¡å·"""
    signal_type: ConflictEvidence
    value: float  # 0-1
    confidence: float  # 0-1
    evidence_text: str
    processing_time: float
    explanation: str

@dataclass
class ExplainableDecision:
    """å¯è§£é‡Šçš„å†³ç­–ç»“æœ"""
    should_intervene: bool
    confidence_level: ConfidenceLevel
    thomas_stage: str
    intervention_reason: str
    evidence_chain: List[ConflictSignal]
    conflicting_signals: List[ConflictSignal]
    processing_breakdown: Dict[str, float]
    fallback_used: bool

class HybridConflictAnalyzer:
    """æ··åˆå†²çªåˆ†æå™¨ - è§£å†³æ¨¡å‹å†²çª"""
    
    def __init__(self):
        self.lightweight_threshold = 0.4   # å¿«é€Ÿæ£€æµ‹é˜ˆå€¼
        self.thomas_weight = 0.4          # Thomasæ¨¡å‹æƒé‡
        self.llm_weight = 0.3             # LLMæƒé‡
        self.keyword_weight = 0.3         # å…³é”®è¯æƒé‡
        
        # å®æ—¶æ€§ä¼˜å…ˆçº§
        self.max_llm_wait_time = 400  # ms
        self.early_decision_threshold = 0.7
        
    async def analyze_with_explanation(self, message: str, context: dict) -> ExplainableDecision:
        """å¸¦è§£é‡Šçš„å†²çªåˆ†æ"""
        start_time = asyncio.get_event_loop().time()
        signals = []
        
        # 1. ç«‹å³å¯åŠ¨å¹¶è¡Œåˆ†æ
        tasks = [
            self._lightweight_analysis(message),
            self._thomas_stage_analysis(message, context),
            self._llm_analysis_with_timeout(message, context)
        ]
        
        # 2. ç­‰å¾…å¿«é€Ÿåˆ†æå®Œæˆ
        lightweight_signal, thomas_signal = await asyncio.gather(*tasks[:2])
        signals.extend([lightweight_signal, thomas_signal])
        
        # 3. æ—©æœŸå†³ç­–æ£€æŸ¥
        early_decision = self._check_early_decision(signals)
        if early_decision:
            return self._build_decision(signals, early_decision=True, 
                                      processing_time=asyncio.get_event_loop().time() - start_time)
        
        # 4. ç­‰å¾…LLMåˆ†æï¼ˆæœ‰è¶…æ—¶ï¼‰
        try:
            llm_signal = await asyncio.wait_for(tasks[2], timeout=0.4)
            signals.append(llm_signal)
        except asyncio.TimeoutError:
            logger.warning("LLMåˆ†æè¶…æ—¶ï¼Œä½¿ç”¨å¿«é€Ÿåˆ†æç»“æœ")
            llm_signal = ConflictSignal(
                signal_type=ConflictEvidence.LLM_SEMANTIC,
                value=0.0,
                confidence=0.0,
                evidence_text="è¶…æ—¶",
                processing_time=400,
                explanation="LLMåˆ†æè¶…æ—¶ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ"
            )
            signals.append(llm_signal)
        
        # 5. ç»¼åˆå†³ç­–
        return self._build_decision(signals, early_decision=False,
                                  processing_time=asyncio.get_event_loop().time() - start_time)
    
    async def _lightweight_analysis(self, message: str) -> ConflictSignal:
        """è½»é‡çº§åˆ†æ"""
        start_time = asyncio.get_event_loop().time()
        
        conflict_indicators = {
            "emotion_words": ["æ„¤æ€’", "ç”Ÿæ°”", "ä¸æ»¡", "angry", "frustrated"],
            "disagreement": ["ä¸åŒæ„", "åå¯¹", "é”™è¯¯", "wrong", "disagree"],
            "personal_attack": ["ä½ æ€»æ˜¯", "ä½ ä»ä¸", "you always", "you never"],
            "intensity": ["!", "å®Œå…¨", "ç»å¯¹", "absolutely", "completely"]
        }
        
        score = 0.0
        evidence = []
        
        for category, keywords in conflict_indicators.items():
            count = sum(1 for word in keywords if word.lower() in message.lower())
            if count > 0:
                category_score = min(count * 0.2, 0.4)
                score += category_score
                evidence.append(f"{category}: {count}ä¸ªåŒ¹é…")
        
        processing_time = (asyncio.get_event_loop().time() - start_time) * 1000
        
        return ConflictSignal(
            signal_type=ConflictEvidence.KEYWORD_BASED,
            value=min(score, 1.0),
            confidence=0.8 if score > 0.3 else 0.5,
            evidence_text="; ".join(evidence),
            processing_time=processing_time,
            explanation=f"å…³é”®è¯åŒ¹é…åˆ†æ: {score:.2f}åˆ†"
        )
    
    async def _thomas_stage_analysis(self, message: str, context: dict) -> ConflictSignal:
        """Thomasé˜¶æ®µåˆ†æ"""
        start_time = asyncio.get_event_loop().time()
        
        stage_indicators = {
            "frustration": ["æŒ«æŠ˜", "é˜»ç¢", "frustrated", "blocked"],
            "conceptualization": ["æˆ‘è®¤ä¸º", "é—®é¢˜æ˜¯", "I think", "the issue"],
            "behavior": ["æˆ‘è¦", "æˆ‘ä¼š", "I will", "going to"],
            "interaction": ["ä½ è¯´", "you said", "å›åº”", "respond"],
            "outcomes": ["ç»“æœ", "åæœ", "result", "consequence"]
        }
        
        stage_scores = {}
        for stage, keywords in stage_indicators.items():
            score = sum(1 for word in keywords if word.lower() in message.lower())
            stage_scores[stage] = score
        
        # æ‰¾åˆ°æœ€é«˜åˆ†é˜¶æ®µ
        max_stage = max(stage_scores, key=stage_scores.get) if any(stage_scores.values()) else "unknown"
        max_score = stage_scores.get(max_stage, 0)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ä½³å¹²é¢„æ—¶æœº
        is_optimal_timing = (max_stage == "conceptualization" and max_score > 0)
        
        conflict_value = 0.6 if is_optimal_timing else min(max_score * 0.2, 0.5)
        processing_time = (asyncio.get_event_loop().time() - start_time) * 1000
        
        return ConflictSignal(
            signal_type=ConflictEvidence.BEHAVIORAL_SIGNAL,
            value=conflict_value,
            confidence=0.9 if is_optimal_timing else 0.6,
            evidence_text=f"é˜¶æ®µ: {max_stage}, åˆ†æ•°: {max_score}",
            processing_time=processing_time,
            explanation=f"Thomasæ¨¡å‹è¯†åˆ«ä¸º{max_stage}é˜¶æ®µï¼Œæœ€ä½³æ—¶æœº: {is_optimal_timing}"
        )
    
    async def _llm_analysis_with_timeout(self, message: str, context: dict) -> ConflictSignal:
        """å¸¦è¶…æ—¶çš„LLMåˆ†æ"""
        start_time = asyncio.get_event_loop().time()
        
        try:
            # æ¨¡æ‹ŸLLM APIè°ƒç”¨
            await asyncio.sleep(0.3)  # æ¨¡æ‹Ÿ300mså»¶è¿Ÿ
            
            # ç®€åŒ–çš„LLMåˆ†æé€»è¾‘
            score = 0.5 if any(word in message.lower() for word in ["å†²çª", "äº‰åµ", "åˆ†æ­§"]) else 0.3
            
            processing_time = (asyncio.get_event_loop().time() - start_time) * 1000
            
            return ConflictSignal(
                signal_type=ConflictEvidence.LLM_SEMANTIC,
                value=score,
                confidence=0.8,
                evidence_text="è¯­ä¹‰åˆ†æå®Œæˆ",
                processing_time=processing_time,
                explanation=f"LLMè¯­ä¹‰ç†è§£åˆ†æ: {score:.2f}åˆ†"
            )
            
        except Exception as e:
            processing_time = (asyncio.get_event_loop().time() - start_time) * 1000
            return ConflictSignal(
                signal_type=ConflictEvidence.LLM_SEMANTIC,
                value=0.0,
                confidence=0.0,
                evidence_text=f"åˆ†æå¤±è´¥: {str(e)}",
                processing_time=processing_time,
                explanation="LLMåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°åˆ†æ"
            )
    
    def _check_early_decision(self, signals: List[ConflictSignal]) -> Optional[bool]:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ—©æœŸå†³ç­–"""
        # å¦‚æœThomasæ¨¡å‹é«˜ç½®ä¿¡åº¦è¯†åˆ«æœ€ä½³æ—¶æœº
        thomas_signal = next((s for s in signals if s.signal_type == ConflictEvidence.BEHAVIORAL_SIGNAL), None)
        if thomas_signal and thomas_signal.confidence > 0.8 and thomas_signal.value > 0.5:
            return True
        
        # å¦‚æœå…³é”®è¯æ£€æµ‹é«˜åˆ†
        keyword_signal = next((s for s in signals if s.signal_type == ConflictEvidence.KEYWORD_BASED), None)
        if keyword_signal and keyword_signal.value > self.early_decision_threshold:
            return True
        
        return None
    
    def _build_decision(self, signals: List[ConflictSignal], early_decision: bool, processing_time: float) -> ExplainableDecision:
        """æ„å»ºå¯è§£é‡Šçš„å†³ç­–"""
        
        # è®¡ç®—åŠ æƒåˆ†æ•°
        total_score = 0.0
        total_weight = 0.0
        evidence_chain = []
        conflicting_signals = []
        
        weights = {
            ConflictEvidence.KEYWORD_BASED: self.keyword_weight,
            ConflictEvidence.BEHAVIORAL_SIGNAL: self.thomas_weight,
            ConflictEvidence.LLM_SEMANTIC: self.llm_weight
        }
        
        for signal in signals:
            weight = weights.get(signal.signal_type, 0.1)
            if signal.confidence > 0.3:  # åªè€ƒè™‘é«˜ç½®ä¿¡åº¦ä¿¡å·
                total_score += signal.value * weight * signal.confidence
                total_weight += weight * signal.confidence
                evidence_chain.append(signal)
            else:
                conflicting_signals.append(signal)
        
        final_score = total_score / total_weight if total_weight > 0 else 0.0
        
        # å†³ç­–é€»è¾‘
        should_intervene = final_score > 0.35
        
        # ç½®ä¿¡åº¦ç­‰çº§
        if final_score > 0.8:
            confidence_level = ConfidenceLevel.HIGH
        elif final_score > 0.5:
            confidence_level = ConfidenceLevel.MEDIUM
        elif final_score > 0.3:
            confidence_level = ConfidenceLevel.LOW
        else:
            confidence_level = ConfidenceLevel.UNCERTAIN
        
        # Thomasé˜¶æ®µåˆ¤æ–­
        thomas_signal = next((s for s in signals if s.signal_type == ConflictEvidence.BEHAVIORAL_SIGNAL), None)
        thomas_stage = thomas_signal.evidence_text.split(",")[0] if thomas_signal else "æœªçŸ¥"
        
        # å¹²é¢„åŸå› 
        intervention_reason = self._generate_intervention_reason(final_score, evidence_chain, early_decision)
        
        # å¤„ç†æ—¶é—´åˆ†è§£
        processing_breakdown = {
            signal.signal_type.value: signal.processing_time 
            for signal in signals
        }
        
        return ExplainableDecision(
            should_intervene=should_intervene,
            confidence_level=confidence_level,
            thomas_stage=thomas_stage,
            intervention_reason=intervention_reason,
            evidence_chain=evidence_chain,
            conflicting_signals=conflicting_signals,
            processing_breakdown=processing_breakdown,
            fallback_used=early_decision
        )
    
    def _generate_intervention_reason(self, score: float, evidence: List[ConflictSignal], early_decision: bool) -> str:
        """ç”Ÿæˆå¹²é¢„åŸå› è¯´æ˜"""
        if score > 0.8:
            return f"é«˜å†²çªé£é™© (åˆ†æ•°: {score:.2f}) - æ£€æµ‹åˆ°å¼ºçƒˆå†²çªä¿¡å·"
        elif score > 0.5:
            return f"ä¸­ç­‰å†²çªé£é™© (åˆ†æ•°: {score:.2f}) - å»ºè®®é¢„é˜²æ€§å¹²é¢„"
        elif score > 0.35:
            return f"è½»å¾®å†²çªå€¾å‘ (åˆ†æ•°: {score:.2f}) - æ¸©å’Œæé†’"
        else:
            return f"æ— éœ€å¹²é¢„ (åˆ†æ•°: {score:.2f}) - å¯¹è¯æ­£å¸¸"

class ExplainableInterventionBot:
    """å¯è§£é‡Šæ€§å†²çªå¹²é¢„æœºå™¨äºº"""
    
    def __init__(self):
        self.analyzer = HybridConflictAnalyzer()
        
    async def process_message_with_explanation(self, message: str, author: str, channel_id: str) -> Optional[str]:
        """å¤„ç†æ¶ˆæ¯å¹¶ç”Ÿæˆè§£é‡Š"""
        
        # åˆ†æå†²çª
        decision = await self.analyzer.analyze_with_explanation(
            message, 
            {"channel_id": channel_id, "author": author}
        )
        
        # è®°å½•è¯¦ç»†æ—¥å¿—
        logger.info(f"ğŸ” å†²çªåˆ†æç»“æœ:")
        logger.info(f"   å†³ç­–: {'å¹²é¢„' if decision.should_intervene else 'ä¸å¹²é¢„'}")
        logger.info(f"   ç½®ä¿¡åº¦: {decision.confidence_level.value}")
        logger.info(f"   Thomasé˜¶æ®µ: {decision.thomas_stage}")
        logger.info(f"   å¤„ç†æ—¶é—´: {sum(decision.processing_breakdown.values()):.1f}ms")
        
        for signal in decision.evidence_chain:
            logger.info(f"   âœ… {signal.explanation}")
        
        for signal in decision.conflicting_signals:
            logger.info(f"   âš ï¸ {signal.explanation}")
        
        if decision.should_intervene:
            # ç”Ÿæˆå¹²é¢„æ¶ˆæ¯
            intervention = self._generate_transparent_intervention(decision)
            return intervention
        
        return None
    
    def _generate_transparent_intervention(self, decision: ExplainableDecision) -> str:
        """ç”Ÿæˆé€æ˜çš„å¹²é¢„æ¶ˆæ¯"""
        
        # åŸºç¡€å¹²é¢„æ¶ˆæ¯
        base_messages = {
            ConfidenceLevel.HIGH: "æˆ‘æ³¨æ„åˆ°å¯¹è¯ä¸­å‡ºç°äº†æ¯”è¾ƒå¼ºçƒˆçš„åˆ†æ­§ã€‚",
            ConfidenceLevel.MEDIUM: "æˆ‘æ„Ÿè§‰åˆ°ä¸€äº›ç´§å¼ æ°”æ°›ã€‚",
            ConfidenceLevel.LOW: "è®©æˆ‘ä»¬ä¿æŒå†·é™ç»§ç»­è®¨è®ºã€‚"
        }
        
        base_msg = base_messages.get(decision.confidence_level, "æˆ‘æ¥å¸®åŠ©å¤§å®¶æ›´å¥½åœ°æ²Ÿé€šã€‚")
        
        # æ·»åŠ å¯è§£é‡Šæ€§ä¿¡æ¯ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        debug_info = f"\n\nğŸ’¡ å¹²é¢„ä¾æ®: {decision.intervention_reason}"
        debug_info += f"\nğŸ¯ åˆ†æé˜¶æ®µ: {decision.thomas_stage}"
        debug_info += f"\nâš¡ å“åº”æ—¶é—´: {sum(decision.processing_breakdown.values()):.0f}ms"
        
        if decision.fallback_used:
            debug_info += "\nğŸš€ ä½¿ç”¨å¿«é€Ÿå†³ç­–æ¨¡å¼"
        
        return base_msg + debug_info

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    bot = ExplainableInterventionBot()
    
    # æµ‹è¯•æ¶ˆæ¯
    test_messages = [
        "æˆ‘è§‰å¾—ä½ çš„æƒ³æ³•å®Œå…¨é”™è¯¯ï¼",
        "æˆ‘è®¤ä¸ºè¿™é‡Œçš„é—®é¢˜æ˜¯æ²Ÿé€šä¸å¤Ÿ",
        "ä½ æ€»æ˜¯ä¸å¬æˆ‘çš„æ„è§",
        "ä»Šå¤©å¤©æ°”ä¸é”™å‘¢"
    ]
    
    for msg in test_messages:
        print(f"\nğŸ“¨ æµ‹è¯•æ¶ˆæ¯: {msg}")
        result = await bot.process_message_with_explanation(msg, "æµ‹è¯•ç”¨æˆ·", "test_channel")
        if result:
            print(f"ğŸ¤– å¹²é¢„: {result}")
        else:
            print("âœ… æ— éœ€å¹²é¢„")

if __name__ == "__main__":
    asyncio.run(main()) 