"""
ä¿®å¤ç‰ˆçš„GPT-4å†²çªæ£€æµ‹ç³»ç»Ÿ
"""

import asyncio
import os
import logging
from datetime import datetime
from collections import deque
from enum import Enum
from typing import List, Dict, Optional
from dataclasses import dataclass
import json
import aiohttp
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

class TKIStrategy(Enum):
    """TKIå¹²é¢„ç­–ç•¥"""
    COLLABORATING = "åä½œ"
    ACCOMMODATING = "è¿å°±"
    COMPETING = "ç«äº‰"
    AVOIDING = "å›é¿"
    COMPROMISING = "å¦¥å"

class ConflictLevel(Enum):
    """å†²çªç­‰çº§"""
    NONE = "æ— å†²çª"
    MILD = "è½»å¾®åˆ†æ­§"
    MODERATE = "ä¸­ç­‰å†²çª"
    HIGH = "ä¸¥é‡å†²çª"
    CRITICAL = "å±é™©å†²çª"

@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡"""
    speaker: str
    content: str
    timestamp: datetime
    turn_number: int

@dataclass
class LLMAnalysisResult:
    """LLMåˆ†æç»“æœ"""
    conflict_score: float
    conflict_level: ConflictLevel
    conflict_type: str
    emotional_tone: str
    escalation_risk: float
    recommended_strategy: TKIStrategy
    intervention_message: str
    analysis_reasoning: str
    should_intervene: bool

class GPT4ConflictAnalyzer:
    """GPT-4å†²çªåˆ†æå™¨ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.conversation_history = deque(maxlen=10)
        
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
    
    async def analyze_conversation(self, new_speaker: str, new_message: str) -> LLMAnalysisResult:
        """åˆ†æå¯¹è¯å¹¶è¿”å›ç»“æœ"""
        
        # è°ƒè¯•ï¼šæ‰“å°æ¥æ”¶åˆ°çš„æ¶ˆæ¯
        logger.info(f"æ¥æ”¶åˆ°æ¶ˆæ¯: {new_speaker}: {new_message}")
        
        # æ·»åŠ æ–°æ¶ˆæ¯åˆ°å†å²
        turn = ConversationTurn(
            speaker=new_speaker,
            content=new_message,
            timestamp=datetime.now(),
            turn_number=len(self.conversation_history) + 1
        )
        self.conversation_history.append(turn)
        
        # ä»ç¬¬2è½®å¼€å§‹åˆ†æ
        if len(self.conversation_history) >= 2:
            return await self._call_gpt4_analysis()
        else:
            return LLMAnalysisResult(
                conflict_score=0.0,
                conflict_level=ConflictLevel.NONE,
                conflict_type="å¯¹è¯åˆšå¼€å§‹",
                emotional_tone="ä¸­æ€§",
                escalation_risk=0.0,
                recommended_strategy=TKIStrategy.COLLABORATING,
                intervention_message="",
                analysis_reasoning="å¯¹è¯è½®æ¬¡ä¸è¶³ï¼Œç»§ç»­è§‚å¯Ÿ",
                should_intervene=False
            )
    
    async def _call_gpt4_analysis(self) -> LLMAnalysisResult:
        """è°ƒç”¨GPT-4è¿›è¡Œåˆ†æ"""
        
        # æ„å»ºå¯¹è¯å†å²
        conversation_text = self._format_conversation_for_llm()
        
        logger.info(f"å‘é€ç»™GPT-4çš„å¯¹è¯: {conversation_text}")
        
        # ç®€åŒ–çš„ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯å†²çªæ£€æµ‹ä¸“å®¶ã€‚åˆ†æå¯¹è¯ä¸­çš„å†²çªç¨‹åº¦ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥æ”»å‡»æ€§è¯­è¨€
2. é—´æ¥ä¸æ»¡è¡¨è¾¾
3. æ—¶é—´å‹åŠ›å’Œè´£ä»»æ¨å¸
4. æƒ…ç»ªå‡çº§è¶‹åŠ¿

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼ˆä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼‰ï¼š
{
    "conflict_score": æ•°å€¼0-1,
    "conflict_level": "æ— å†²çª/è½»å¾®åˆ†æ­§/ä¸­ç­‰å†²çª/ä¸¥é‡å†²çª/å±é™©å†²çª",
    "conflict_type": "å†²çªç±»å‹æè¿°",
    "emotional_tone": "æƒ…ç»ªæè¿°",
    "escalation_risk": æ•°å€¼0-1,
    "recommended_strategy": "åä½œ/è¿å°±/ç«äº‰/å›é¿/å¦¥å",
    "should_intervene": trueæˆ–false,
    "intervention_message": "å¹²é¢„æ¶ˆæ¯",
    "analysis_reasoning": "åˆ†æåŸå› "
}"""

        user_prompt = f"åˆ†æä»¥ä¸‹å¯¹è¯çš„å†²çªç¨‹åº¦ï¼š\n\n{conversation_text}"

        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-4',
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'temperature': 0.1,  # æ›´ä½æ¸©åº¦ä¿è¯æ ¼å¼ä¸€è‡´æ€§
                'max_tokens': 800
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f'{self.base_url}/chat/completions',
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"GPT-4 API error: {response.status} - {error_text}")
                        return self._create_fallback_result(f"APIé”™è¯¯: {response.status}")
                    
                    result = await response.json()
                    
                    if 'choices' not in result or not result['choices']:
                        logger.error("GPT-4 API returned no choices")
                        return self._create_fallback_result("APIè¿”å›ä¸ºç©º")
                    
                    # è·å–GPT-4çš„å›å¤
                    gpt_response = result['choices'][0]['message']['content'].strip()
                    logger.info(f"GPT-4åŸå§‹å›å¤: {gpt_response}")
                    
                    # è§£æå›å¤
                    return self._parse_gpt4_response(gpt_response)
                    
        except asyncio.TimeoutError:
            logger.error("GPT-4 API timeout")
            return self._create_fallback_result("APIè¶…æ—¶")
        except Exception as e:
            logger.error(f"GPT-4 API call failed: {e}")
            return self._create_fallback_result(f"APIé”™è¯¯: {str(e)}")
    
    def _format_conversation_for_llm(self) -> str:
        """æ ¼å¼åŒ–å¯¹è¯ä¾›LLMåˆ†æ"""
        conversation_lines = []
        
        for turn in self.conversation_history:
            conversation_lines.append(f"{turn.speaker}: {turn.content}")
        
        return "\n".join(conversation_lines)
    
    def _parse_gpt4_response(self, response: str) -> LLMAnalysisResult:
        """è§£æGPT-4çš„JSONå“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            response = response.strip()
            
            # å¤šç§æ–¹å¼å°è¯•æå–JSON
            json_str = None
            
            # æ–¹æ³•1: ç›´æ¥è§£æ
            try:
                json_str = response
                data = json.loads(json_str)
            except json.JSONDecodeError:
                pass
            
            # æ–¹æ³•2: æŸ¥æ‰¾å¤§æ‹¬å·
            if json_str is None:
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    try:
                        data = json.loads(json_str)
                    except json.JSONDecodeError:
                        json_str = None
            
            # æ–¹æ³•3: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¸…ç†
            if json_str is None:
                import re
                # ç§»é™¤markdownä»£ç å—æ ‡è®°
                cleaned = re.sub(r'```json\s*|\s*```', '', response)
                cleaned = cleaned.strip()
                try:
                    data = json.loads(cleaned)
                    json_str = cleaned
                except json.JSONDecodeError:
                    pass
            
            if json_str is None:
                logger.error(f"æ— æ³•è§£æGPT-4å“åº”ä¸ºJSON: {response}")
                return self._create_fallback_result("JSONè§£æå¤±è´¥")
            
            # æ˜ å°„æšä¸¾å€¼
            level_map = {
                "æ— å†²çª": ConflictLevel.NONE,
                "è½»å¾®åˆ†æ­§": ConflictLevel.MILD,
                "ä¸­ç­‰å†²çª": ConflictLevel.MODERATE,
                "ä¸¥é‡å†²çª": ConflictLevel.HIGH,
                "å±é™©å†²çª": ConflictLevel.CRITICAL
            }
            
            strategy_map = {
                "åä½œ": TKIStrategy.COLLABORATING,
                "è¿å°±": TKIStrategy.ACCOMMODATING,
                "ç«äº‰": TKIStrategy.COMPETING,
                "å›é¿": TKIStrategy.AVOIDING,
                "å¦¥å": TKIStrategy.COMPROMISING
            }
            
            return LLMAnalysisResult(
                conflict_score=float(data.get('conflict_score', 0.0)),
                conflict_level=level_map.get(data.get('conflict_level', 'æ— å†²çª'), ConflictLevel.NONE),
                conflict_type=data.get('conflict_type', 'æœªçŸ¥'),
                emotional_tone=data.get('emotional_tone', 'ä¸­æ€§'),
                escalation_risk=float(data.get('escalation_risk', 0.0)),
                recommended_strategy=strategy_map.get(data.get('recommended_strategy', 'åä½œ'), TKIStrategy.COLLABORATING),
                intervention_message=data.get('intervention_message', ''),
                analysis_reasoning=data.get('analysis_reasoning', ''),
                should_intervene=bool(data.get('should_intervene', False))
            )
            
        except Exception as e:
            logger.error(f"è§£æGPT-4å“åº”å¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response}")
            return self._create_fallback_result(f"è§£æé”™è¯¯: {str(e)}")
    
    def _create_fallback_result(self, error_reason: str) -> LLMAnalysisResult:
        """åˆ›å»ºé™çº§ç»“æœ"""
        return LLMAnalysisResult(
            conflict_score=0.0,
            conflict_level=ConflictLevel.NONE,
            conflict_type="åˆ†æå¤±è´¥",
            emotional_tone="æœªçŸ¥",
            escalation_risk=0.0,
            recommended_strategy=TKIStrategy.COLLABORATING,
            intervention_message="",
            analysis_reasoning=f"GPT-4åˆ†æå¤±è´¥: {error_reason}",
            should_intervene=False
        )

# å…¨å±€åˆ†æå™¨
llm_analyzer = GPT4ConflictAnalyzer()
message_count = 0

def format_score_bar(score: float, width: int = 10) -> str:
    """æ ¼å¼åŒ–åˆ†æ•°æ¡å½¢å›¾"""
    filled = int(score * width)
    return "â–ˆ" * filled + "â–‘" * (width - filled)

def get_color_indicator(score: float) -> str:
    """è·å–é¢œè‰²æŒ‡ç¤ºå™¨"""
    if score >= 0.8:
        return "ğŸ”´"
    elif score >= 0.6:
        return "ğŸŸ "
    elif score >= 0.4:
        return "ğŸŸ¡"
    elif score >= 0.2:
        return "ğŸŸ¢"
    else:
        return "âšª"

def print_startup_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    start_time = datetime.now()
    banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  ğŸ¤– GPT-4æ™ºèƒ½å†²çªæ£€æµ‹æœºå™¨äºº - ä¿®å¤ç‰ˆ v2.0                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ å¯åŠ¨æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}                                                â•‘
â•‘ åˆ†æå¼•æ“: ğŸ§  GPT-4 (æ¸©åº¦=0.1, é«˜ç¨³å®šæ€§)                                            â•‘
â•‘ åˆ†æèµ·ç‚¹: ç¬¬2è½®å¯¹è¯å¼€å§‹                                                            â•‘
â•‘ ä¿®å¤å†…å®¹: JSONè§£æ | æ¶ˆæ¯è·å– | é”™è¯¯å¤„ç†                                            â•‘
â•‘                                                                              â•‘
â•‘ æ£€æµ‹èŒƒå›´: æ—¶é—´å‹åŠ› | è´£ä»»æ¨å¸ | æƒ…ç»ªå‡çº§ | ç½‘ç»œç”¨è¯­ | å¾®å¦™æš—ç¤º                        â•‘
â•‘ å›¾ä¾‹: ğŸš¨=å¹²é¢„ âœ…=æ­£å¸¸ ğŸ”´ğŸŸ ğŸŸ¡ğŸŸ¢âšª=å†²çªç­‰çº§ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘=å¼ºåº¦æ¡                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)

async def log_llm_analysis(message: str, author: str, result: LLMAnalysisResult, processing_time: float):
    """è®°å½•LLMåˆ†æç»“æœ"""
    global message_count
    message_count += 1
    
    timestamp = datetime.now().strftime('%H:%M:%S')
    status = "ğŸš¨" if result.should_intervene else "âœ…"
    
    # ç¡®ä¿æ¶ˆæ¯å†…å®¹æ­£ç¡®æ˜¾ç¤º
    message_preview = message[:40] + "..." if len(message) > 40 else message
    if not message.strip():
        message_preview = "[ç©ºæ¶ˆæ¯]"
    
    score_bar = format_score_bar(result.conflict_score)
    color_indicator = get_color_indicator(result.conflict_score)
    
    print(f"""
{status} [{timestamp}] {author} (è½®æ¬¡#{message_count})
ğŸ“ {message_preview}
ğŸ“Š å†²çªåˆ†æ•°: {result.conflict_score:.2f} {score_bar} {color_indicator}
ğŸ” å†²çªç±»å‹: {result.conflict_type}
ğŸ˜Š æƒ…ç»ªè‰²è°ƒ: {result.emotional_tone}
ğŸ“ˆ å‡çº§é£é™©: {result.escalation_risk:.2f}
ğŸ¯ æ¨èç­–ç•¥: {result.recommended_strategy.value}
â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.1f}ms
ğŸ’­ GPT-4åˆ†æ: {result.analysis_reasoning}
""".strip())
    
    if result.should_intervene:
        print(f"ğŸ’¬ æ™ºèƒ½å¹²é¢„: {result.intervention_message}")
    
    print("â”€" * 70)

class LLMConflictBot:
    """åŸºäºLLMçš„å†²çªæ£€æµ‹æœºå™¨äººï¼ˆä¿®å¤ç‰ˆï¼‰"""
    
    def __init__(self):
        self.discord_client = None
        
    async def start(self, token: str):
        """å¯åŠ¨Discordæœºå™¨äºº"""
        import discord
        
        print_startup_banner()
        
        class DiscordBot(discord.Client):
            def __init__(self):
                super().__init__(intents=discord.Intents.default())
                
            async def on_ready(self):
                logger.info(f'ğŸš€ æœºå™¨äººå·²ç™»å½•ä¸º {self.user}')
                print(f"\nğŸŒŸ {self.user} å·²ä¸Šçº¿ï¼ŒGPT-4å¼€å§‹åˆ†æ...")
                print("=" * 70)
                
            async def on_message(self, message):
                if message.author == self.user:
                    return
                
                # ç¡®ä¿è·å–åˆ°æ¶ˆæ¯å†…å®¹
                message_content = message.content
                author_name = message.author.display_name
                
                # è°ƒè¯•è¾“å‡º
                logger.info(f"Discordæ¶ˆæ¯: {author_name}: {message_content}")
                
                start_processing = asyncio.get_event_loop().time()
                
                try:
                    # ä½¿ç”¨GPT-4åˆ†æ
                    result = await llm_analyzer.analyze_conversation(author_name, message_content)
                    
                    processing_time = (asyncio.get_event_loop().time() - start_processing) * 1000
                    
                    # è®°å½•åˆ†æç»“æœ
                    await log_llm_analysis(message_content, author_name, result, processing_time)
                    
                    # å‘é€å¹²é¢„æ¶ˆæ¯
                    if result.should_intervene:
                        await message.channel.send(result.intervention_message)
                        
                except Exception as e:
                    logger.error(f"LLMåˆ†æå¤±è´¥: {e}")
                    print(f"âŒ LLMåˆ†æå¤±è´¥: {e}")
        
        self.discord_client = DiscordBot()
        await self.discord_client.start(token)

async def main():
    """ä¸»å‡½æ•°"""
    token = os.getenv('DISCORD_TOKEN')
    if not token:
        logger.error("DISCORD_TOKEN not found")
        return
    
    # æ£€æŸ¥OpenAI API Key
    if not os.getenv('OPENAI_API_KEY'):
        logger.error("OPENAI_API_KEY not found")
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OPENAI_API_KEY")
        return
    
    bot = LLMConflictBot()
    
    try:
        logger.info("Starting GPT-4 powered conflict intervention bot (Fixed)...")
        await bot.start(token)
    except KeyboardInterrupt:
        logger.info("Bot shutting down...")
        print(f"\nğŸ›‘ æœºå™¨äººå·²åœæ­¢ - å…±åˆ†æ {message_count} æ¡æ¶ˆæ¯")
    except Exception as e:
        logger.error(f"Startup failed: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 