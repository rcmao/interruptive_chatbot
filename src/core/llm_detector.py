"""
åŸºäºGPT-4çš„çº¯LLMå†²çªæ£€æµ‹ç³»ç»Ÿ
å®Œå…¨ä¾èµ–å¤§æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›
"""

import asyncio
import os
import logging
from datetime import datetime
from collections import deque
from enum import Enum
from typing import List, Dict, Optional
from dataclasses import dataclass
import json
import aiohttp
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

class TKIStrategy(Enum):
    """TKIå¹²é¢„ç­–ç•¥"""
    COLLABORATING = "åä½œ"
    ACCOMMODATING = "è¿å°±"
    COMPETING = "ç«äº‰"
    AVOIDING = "å›é¿"
    COMPROMISING = "å¦¥å"

class ConflictLevel(Enum):
    """å†²çªç­‰çº§"""
    NONE = "æ— å†²çª"
    MILD = "è½»å¾®åˆ†æ­§"
    MODERATE = "ä¸­ç­‰å†²çª"
    HIGH = "ä¸¥é‡å†²çª"
    CRITICAL = "å±é™©å†²çª"

@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡"""
    speaker: str
    content: str
    timestamp: datetime
    turn_number: int

@dataclass
class LLMAnalysisResult:
    """LLMåˆ†æç»“æœ"""
    conflict_score: float          # 0-1 å†²çªå¼ºåº¦
    conflict_level: ConflictLevel
    conflict_type: str             # å†²çªç±»å‹æè¿°
    emotional_tone: str            # æƒ…ç»ªæè¿°
    escalation_risk: float         # 0-1 å‡çº§é£é™©
    recommended_strategy: TKIStrategy
    intervention_message: str
    analysis_reasoning: str
    should_intervene: bool

class GPT4ConflictAnalyzer:
    """GPT-4å†²çªåˆ†æå™¨"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_API_BASE', 'https://api.openai.com/v1')
        self.conversation_history = deque(maxlen=10)
        
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
    
    async def analyze_conversation(self, new_speaker: str, new_message: str) -> LLMAnalysisResult:
        """åˆ†æå¯¹è¯å¹¶è¿”å›ç»“æœ"""
        
        # æ·»åŠ æ–°æ¶ˆæ¯åˆ°å†å²
        turn = ConversationTurn(
            speaker=new_speaker,
            content=new_message,
            timestamp=datetime.now(),
            turn_number=len(self.conversation_history) + 1
        )
        self.conversation_history.append(turn)
        
        # ä»ç¬¬2è½®å¼€å§‹åˆ†æï¼ˆç»™LLMæ›´æ—©çš„ä»‹å…¥æœºä¼šï¼‰
        if len(self.conversation_history) >= 2:
            return await self._call_gpt4_analysis()
        else:
            return LLMAnalysisResult(
                conflict_score=0.0,
                conflict_level=ConflictLevel.NONE,
                conflict_type="å¯¹è¯åˆšå¼€å§‹",
                emotional_tone="ä¸­æ€§",
                escalation_risk=0.0,
                recommended_strategy=TKIStrategy.COLLABORATING,
                intervention_message="",
                analysis_reasoning="å¯¹è¯è½®æ¬¡ä¸è¶³ï¼Œç»§ç»­è§‚å¯Ÿ",
                should_intervene=False
            )
    
    async def _call_gpt4_analysis(self) -> LLMAnalysisResult:
        """è°ƒç”¨GPT-4è¿›è¡Œåˆ†æ"""
        
        # æ„å»ºå¯¹è¯å†å²
        conversation_text = self._format_conversation_for_llm()
        
        # æ„å»ºåˆ†ææç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†²çªæ£€æµ‹å’Œå¹²é¢„ä¸“å®¶ï¼ŒåŸºäºThomaså†²çªè¿‡ç¨‹æ¨¡å‹å’ŒTKIç†è®ºã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå¯¹è¯ä¸­çš„å†²çªä¿¡å·ï¼ŒåŒ…æ‹¬ï¼š
1. ç›´æ¥å†²çªï¼ˆäº‰åµã€æŒ‡è´£ã€æ”»å‡»ï¼‰
2. é—´æ¥å†²çªï¼ˆæš—ç¤ºã€è®½åˆºã€è¢«åŠ¨æ”»å‡»ï¼‰
3. æƒ…ç»ªå‡çº§ï¼ˆæ²®ä¸§ã€æ„¤æ€’ã€é˜²å¾¡ï¼‰
4. ä»»åŠ¡å†²çªï¼ˆå·¥ä½œæ–¹å¼åˆ†æ­§ã€è´£ä»»æ¨å¸ï¼‰
5. å…³ç³»å†²çªï¼ˆäººé™…ç´§å¼ ã€ä¿¡ä»»é—®é¢˜ï¼‰

è¯·ç‰¹åˆ«æ³¨æ„ï¼š
- ç½‘ç»œç”¨è¯­å’Œä¿šè¯­ï¼ˆå¦‚"å“ˆéº»æ‰¹"ã€"å‚»é€¼"ç­‰ï¼‰
- è¯­æ°”è¯å’Œæ ‡ç‚¹ç¬¦å·çš„æƒ…ç»ªæš—ç¤º
- é‡å¤é—®é¢˜å’Œé˜²å¾¡æ€§è¯­è¨€
- æ—¶é—´å‹åŠ›å’Œè´£ä»»å½’å±
- å¾®å¦™çš„ä¸æ»¡å’ŒæŒ«è´¥æ„Ÿ

TKIç­–ç•¥é€‰æ‹©ï¼š
- åä½œï¼šé—®é¢˜è§£å†³å¯¼å‘ï¼Œå¯»æ±‚åŒèµ¢
- è¿å°±ï¼šå…³ç³»ä¼˜å…ˆï¼Œç¼“è§£æƒ…ç»ª
- ç«äº‰ï¼šæ˜ç¡®ç«‹åœºï¼Œè®¾å®šè¾¹ç•Œ
- å›é¿ï¼šé™æ¸©å¤„ç†ï¼Œæš‚åœè®¨è®º
- å¦¥åï¼šå¯»æ±‚å¹³è¡¡ï¼Œäº’ç›¸è®©æ­¥"""

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¯¹è¯çš„å†²çªç¨‹åº¦ï¼š

{conversation_text}

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "conflict_score": 0.0åˆ°1.0çš„æ•°å€¼,
    "conflict_level": "æ— å†²çª/è½»å¾®åˆ†æ­§/ä¸­ç­‰å†²çª/ä¸¥é‡å†²çª/å±é™©å†²çª",
    "conflict_type": "å†²çªç±»å‹çš„å…·ä½“æè¿°",
    "emotional_tone": "å½“å‰æ•´ä½“æƒ…ç»ªæè¿°",
    "escalation_risk": 0.0åˆ°1.0çš„å‡çº§é£é™©,
    "recommended_strategy": "åä½œ/è¿å°±/ç«äº‰/å›é¿/å¦¥å",
    "should_intervene": true/false,
    "intervention_message": "å¦‚æœéœ€è¦å¹²é¢„ï¼Œæä¾›å…·ä½“çš„å¹²é¢„æ¶ˆæ¯",
    "analysis_reasoning": "è¯¦ç»†çš„åˆ†æä¾æ®å’Œæ¨ç†è¿‡ç¨‹"
}}

æ³¨æ„ï¼š
- å³ä½¿æ˜¯çœ‹ä¼¼æ¸©å’Œçš„è¡¨è¾¾ï¼Œä¹Ÿè¦ä»”ç»†åˆ†ææ½œåœ¨çš„å†²çªä¿¡å·
- ç½‘ç»œç”¨è¯­å’Œè„è¯åº”è¯¥è¢«è¯†åˆ«ä¸ºé«˜å†²çª
- è€ƒè™‘ä¸Šä¸‹æ–‡å’Œå¯¹è¯å‘å±•è¶‹åŠ¿"""

        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'gpt-4',
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'temperature': 0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯åˆ†æçš„ä¸€è‡´æ€§
                'max_tokens': 1000
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f'{self.base_url}/chat/completions',
                    headers=headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"GPT-4 API error: {response.status} - {error_text}")
                        return self._create_fallback_result("APIè°ƒç”¨å¤±è´¥")
                    
                    result = await response.json()
                    
                    if 'choices' not in result or not result['choices']:
                        logger.error("GPT-4 API returned no choices")
                        return self._create_fallback_result("APIè¿”å›ä¸ºç©º")
                    
                    # è§£æGPT-4çš„å›å¤
                    gpt_response = result['choices'][0]['message']['content']
                    return self._parse_gpt4_response(gpt_response)
                    
        except asyncio.TimeoutError:
            logger.error("GPT-4 API timeout")
            return self._create_fallback_result("APIè¶…æ—¶")
        except Exception as e:
            logger.error(f"GPT-4 API call failed: {e}")
            return self._create_fallback_result(f"APIé”™è¯¯: {str(e)}")
    
    def _format_conversation_for_llm(self) -> str:
        """æ ¼å¼åŒ–å¯¹è¯ä¾›LLMåˆ†æ"""
        conversation_lines = []
        
        for turn in self.conversation_history:
            conversation_lines.append(f"{turn.speaker}: {turn.content}")
        
        return "\n".join(conversation_lines)
    
    def _parse_gpt4_response(self, response: str) -> LLMAnalysisResult:
        """è§£æGPT-4çš„JSONå“åº”"""
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                logger.error("No JSON found in GPT-4 response")
                return self._create_fallback_result("å“åº”æ ¼å¼é”™è¯¯")
            
            json_str = response[json_start:json_end]
            data = json.loads(json_str)
            
            # æ˜ å°„å†²çªç­‰çº§
            level_map = {
                "æ— å†²çª": ConflictLevel.NONE,
                "è½»å¾®åˆ†æ­§": ConflictLevel.MILD,
                "ä¸­ç­‰å†²çª": ConflictLevel.MODERATE,
                "ä¸¥é‡å†²çª": ConflictLevel.HIGH,
                "å±é™©å†²çª": ConflictLevel.CRITICAL
            }
            
            # æ˜ å°„TKIç­–ç•¥
            strategy_map = {
                "åä½œ": TKIStrategy.COLLABORATING,
                "è¿å°±": TKIStrategy.ACCOMMODATING,
                "ç«äº‰": TKIStrategy.COMPETING,
                "å›é¿": TKIStrategy.AVOIDING,
                "å¦¥å": TKIStrategy.COMPROMISING
            }
            
            return LLMAnalysisResult(
                conflict_score=float(data.get('conflict_score', 0.0)),
                conflict_level=level_map.get(data.get('conflict_level', 'æ— å†²çª'), ConflictLevel.NONE),
                conflict_type=data.get('conflict_type', 'æœªçŸ¥'),
                emotional_tone=data.get('emotional_tone', 'ä¸­æ€§'),
                escalation_risk=float(data.get('escalation_risk', 0.0)),
                recommended_strategy=strategy_map.get(data.get('recommended_strategy', 'åä½œ'), TKIStrategy.COLLABORATING),
                intervention_message=data.get('intervention_message', ''),
                analysis_reasoning=data.get('analysis_reasoning', ''),
                should_intervene=bool(data.get('should_intervene', False))
            )
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse GPT-4 JSON response: {e}")
            logger.error(f"Response content: {response}")
            return self._create_fallback_result("JSONè§£æå¤±è´¥")
        except Exception as e:
            logger.error(f"Error parsing GPT-4 response: {e}")
            return self._create_fallback_result(f"è§£æé”™è¯¯: {str(e)}")
    
    def _create_fallback_result(self, error_reason: str) -> LLMAnalysisResult:
        """åˆ›å»ºé™çº§ç»“æœ"""
        return LLMAnalysisResult(
            conflict_score=0.0,
            conflict_level=ConflictLevel.NONE,
            conflict_type="åˆ†æå¤±è´¥",
            emotional_tone="æœªçŸ¥",
            escalation_risk=0.0,
            recommended_strategy=TKIStrategy.COLLABORATING,
            intervention_message="",
            analysis_reasoning=f"GPT-4åˆ†æå¤±è´¥: {error_reason}",
            should_intervene=False
        )

# å…¨å±€åˆ†æå™¨
llm_analyzer = GPT4ConflictAnalyzer()
message_count = 0

def format_score_bar(score: float, width: int = 10) -> str:
    """æ ¼å¼åŒ–åˆ†æ•°æ¡å½¢å›¾"""
    filled = int(score * width)
    return "â–ˆ" * filled + "â–‘" * (width - filled)

def get_color_indicator(score: float) -> str:
    """è·å–é¢œè‰²æŒ‡ç¤ºå™¨"""
    if score >= 0.8:
        return "ğŸ”´"  # çº¢è‰² - å±é™©
    elif score >= 0.6:
        return "ğŸŸ "  # æ©™è‰² - è­¦å‘Š
    elif score >= 0.4:
        return "ğŸŸ¡"  # é»„è‰² - æ³¨æ„
    elif score >= 0.2:
        return "ğŸŸ¢"  # ç»¿è‰² - è½»å¾®
    else:
        return "âšª"  # ç™½è‰² - æ­£å¸¸

def print_startup_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    start_time = datetime.now()
    banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ¤– GPT-4æ™ºèƒ½å†²çªæ£€æµ‹æœºå™¨äºº - çº¯LLMåˆ†ææ¨¡å¼                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ å¯åŠ¨æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}                                                â•‘
â•‘ åˆ†æå¼•æ“: ğŸ§  GPT-4 Turbo                                                         â•‘
â•‘ åˆ†æèµ·ç‚¹: ç¬¬2è½®å¯¹è¯å¼€å§‹                                                            â•‘
â•‘ æ£€æµ‹èƒ½åŠ›: ç½‘ç»œç”¨è¯­ | å¾®å¦™æš—ç¤º | æƒ…ç»ªå‡çº§ | ä¸Šä¸‹æ–‡ç†è§£                                  â•‘
â•‘                                                                              â•‘
â•‘ ç‰¹è‰²åŠŸèƒ½: æ·±åº¦è¯­ä¹‰ç†è§£ | æ–‡åŒ–èƒŒæ™¯æ„ŸçŸ¥ | å®æ—¶TKIç­–ç•¥ | æ™ºèƒ½å¹²é¢„                          â•‘
â•‘ å›¾ä¾‹: ğŸš¨=å¹²é¢„ âœ…=æ­£å¸¸ ğŸ”´ğŸŸ ğŸŸ¡ğŸŸ¢âšª=å†²çªç­‰çº§ â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘=å¼ºåº¦æ¡                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)

async def log_llm_analysis(message: str, author: str, result: LLMAnalysisResult, processing_time: float):
    """è®°å½•LLMåˆ†æç»“æœ"""
    global message_count
    message_count += 1
    
    timestamp = datetime.now().strftime('%H:%M:%S')
    status = "ğŸš¨" if result.should_intervene else "âœ…"
    message_preview = message[:40] + "..." if len(message) > 40 else message
    
    score_bar = format_score_bar(result.conflict_score)
    color_indicator = get_color_indicator(result.conflict_score)
    
    print(f"""
{status} [{timestamp}] {author} (è½®æ¬¡#{message_count})
ğŸ“ {message_preview}
ğŸ“Š å†²çªåˆ†æ•°: {result.conflict_score:.2f} {score_bar} {color_indicator}
ğŸ” å†²çªç±»å‹: {result.conflict_type}
ğŸ˜Š æƒ…ç»ªè‰²è°ƒ: {result.emotional_tone}
ğŸ“ˆ å‡çº§é£é™©: {result.escalation_risk:.2f}
ğŸ¯ æ¨èç­–ç•¥: {result.recommended_strategy.value}
â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.1f}ms
ğŸ’­ GPT-4åˆ†æ: {result.analysis_reasoning}
""".strip())
    
    if result.should_intervene:
        print(f"ğŸ’¬ æ™ºèƒ½å¹²é¢„: {result.intervention_message}")
    
    print("â”€" * 70)

class LLMConflictBot:
    """åŸºäºLLMçš„å†²çªæ£€æµ‹æœºå™¨äºº"""
    
    def __init__(self):
        self.discord_client = None
        
    async def start(self, token: str):
        """å¯åŠ¨Discordæœºå™¨äºº"""
        import discord
        
        print_startup_banner()
        
        class DiscordBot(discord.Client):
            def __init__(self):
                super().__init__(intents=discord.Intents.default())
                
            async def on_ready(self):
                logger.info(f'ğŸš€ æœºå™¨äººå·²ç™»å½•ä¸º {self.user}')
                print(f"\nğŸŒŸ {self.user} å·²ä¸Šçº¿ï¼ŒGPT-4å¼€å§‹åˆ†æ...")
                print("=" * 70)
                
            async def on_message(self, message):
                if message.author == self.user:
                    return
                
                start_processing = asyncio.get_event_loop().time()
                
                try:
                    # ä½¿ç”¨GPT-4åˆ†æ
                    result = await llm_analyzer.analyze_conversation(
                        message.author.display_name, 
                        message.content
                    )
                    
                    processing_time = (asyncio.get_event_loop().time() - start_processing) * 1000
                    
                    # è®°å½•åˆ†æç»“æœ
                    await log_llm_analysis(message.content, message.author.display_name, result, processing_time)
                    
                    # å‘é€å¹²é¢„æ¶ˆæ¯
                    if result.should_intervene:
                        await message.channel.send(result.intervention_message)
                        
                except Exception as e:
                    logger.error(f"LLMåˆ†æå¤±è´¥: {e}")
                    print(f"âŒ LLMåˆ†æå¤±è´¥: {e}")
        
        self.discord_client = DiscordBot()
        await self.discord_client.start(token)

async def main():
    """ä¸»å‡½æ•°"""
    token = os.getenv('DISCORD_TOKEN')
    if not token:
        logger.error("DISCORD_TOKEN not found")
        return
    
    # æ£€æŸ¥OpenAI API Key
    if not os.getenv('OPENAI_API_KEY'):
        logger.error("OPENAI_API_KEY not found")
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®OPENAI_API_KEY")
        return
    
    bot = LLMConflictBot()
    
    try:
        logger.info("Starting GPT-4 powered conflict intervention bot...")
        await bot.start(token)
    except KeyboardInterrupt:
        logger.info("Bot shutting down...")
        print(f"\nğŸ›‘ æœºå™¨äººå·²åœæ­¢ - å…±åˆ†æ {message_count} æ¡æ¶ˆæ¯")
    except Exception as e:
        logger.error(f"Startup failed: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 