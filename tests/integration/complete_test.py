"""
å®Œæ•´çš„ç³»ç»Ÿæµ‹è¯•å¥—ä»¶
"""

import asyncio
import time
from datetime import datetime

class ComprehensiveTestSuite:
    """ç»¼åˆæµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.test_results = []
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹å®Œæ•´ç³»ç»Ÿæµ‹è¯•")
        print("=" * 60)
        
        # æµ‹è¯•1: å†²çªæ£€æµ‹ç²¾åº¦
        await self.test_conflict_detection_accuracy()
        
        # æµ‹è¯•2: å®æ—¶æ€§èƒ½
        await self.test_real_time_performance()
        
        # æµ‹è¯•3: Thomasé˜¶æ®µè¯†åˆ«
        await self.test_thomas_stages()
        
        # æµ‹è¯•4: è§’è‰²ç‰¹å®šæ£€æµ‹
        await self.test_role_specific_detection()
        
        # æµ‹è¯•5: å¹²é¢„ç­–ç•¥
        await self.test_intervention_strategies()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report()
    
    async def test_conflict_detection_accuracy(self):
        """æµ‹è¯•å†²çªæ£€æµ‹ç²¾åº¦"""
        print("\nğŸ“Š æµ‹è¯•1: å†²çªæ£€æµ‹ç²¾åº¦")
        print("-" * 40)
        
        test_cases = [
            # (æ¶ˆæ¯, æœŸæœ›åˆ†æ•°èŒƒå›´, æœŸæœ›å¹²é¢„)
            ("ä»Šå¤©å¤©æ°”çœŸä¸é”™", (0.0, 0.2), False),
            ("å¤§å®¶å¼€ä¼šè®¨è®ºä¸€ä¸‹", (0.0, 0.3), False),
            ("æˆ‘æœ‰ç‚¹æ‹…å¿ƒè¿›åº¦", (0.2, 0.5), False),
            ("ä½ çš„åšæ³•è®©æˆ‘ä¸æ»¡", (0.4, 0.7), True),
            ("ä½ æ€»æ˜¯ä¸è´Ÿè´£ä»»", (0.5, 0.8), True),
            ("æˆ‘å—å¤Ÿäº†ä½ çš„å€Ÿå£ï¼", (0.6, 1.0), True),
            ("ä½ å°±æ˜¯ä¸ªåºŸç‰©ï¼", (0.7, 1.0), True)
        ]
        
        correct_predictions = 0
        total_tests = len(test_cases)
        
        for message, expected_range, expected_intervention in test_cases:
            # ç®€åŒ–çš„å†²çªæ£€æµ‹ç®—æ³•
            score = self.simple_conflict_detection(message)
            should_intervene = score > 0.35
            
            # æ£€æŸ¥å‡†ç¡®æ€§
            score_correct = expected_range[0] <= score <= expected_range[1]
            intervention_correct = should_intervene == expected_intervention
            
            if score_correct and intervention_correct:
                correct_predictions += 1
                result = "âœ…"
            else:
                result = "âŒ"
            
            print(f"{result} '{message}'")
            print(f"   å¾—åˆ†: {score:.2f} (æœŸæœ›: {expected_range[0]:.1f}-{expected_range[1]:.1f})")
            print(f"   å¹²é¢„: {'æ˜¯' if should_intervene else 'å¦'} (æœŸæœ›: {'æ˜¯' if expected_intervention else 'å¦'})")
            
        accuracy = correct_predictions / total_tests * 100
        print(f"\nğŸ“ˆ æ£€æµ‹ç²¾åº¦: {accuracy:.1f}% ({correct_predictions}/{total_tests})")
        self.test_results.append(("å†²çªæ£€æµ‹ç²¾åº¦", accuracy, accuracy >= 70))
    
    async def test_real_time_performance(self):
        """æµ‹è¯•å®æ—¶æ€§èƒ½"""
        print("\nâš¡ æµ‹è¯•2: å®æ—¶æ€§èƒ½")
        print("-" * 40)
        
        test_messages = [
            "æˆ‘ä»¬éœ€è¦è®¨è®ºä¸€ä¸‹é¡¹ç›®è¿›åº¦",
            "ä½ çš„éƒ¨åˆ†ä»€ä¹ˆæ—¶å€™èƒ½å®Œæˆï¼Ÿ",
            "æˆ‘å¯¹ä½ çš„è¡¨ç°æœ‰äº›ä¸æ»¡",
            "ä½ æ€»æ˜¯æ‰¾å€Ÿå£æ‹–å»¶ä»»åŠ¡",
            "æˆ‘å—å¤Ÿäº†è¿™ç§ä¸è´Ÿè´£çš„æ€åº¦ï¼"
        ]
        
        response_times = []
        
        for i, message in enumerate(test_messages):
            start_time = time.time()
            
            # æ¨¡æ‹Ÿå®Œæ•´æ£€æµ‹æµç¨‹
            score = self.simple_conflict_detection(message)
            should_intervene = score > 0.35
            
            # æ¨¡æ‹Ÿä¸€äº›å¤„ç†å»¶è¿Ÿ
            await asyncio.sleep(0.05)  # 50msæ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            response_time = (time.time() - start_time) * 1000
            response_times.append(response_time)
            
            print(f"æ¶ˆæ¯ {i+1}: {response_time:.1f}ms - {'å¹²é¢„' if should_intervene else 'ç›‘æ§'}")
        
        avg_time = sum(response_times) / len(response_times)
        max_time = max(response_times)
        
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.1f}ms")
        print(f"   æœ€æ…¢å“åº”æ—¶é—´: {max_time:.1f}ms")
        print(f"   å®æ—¶æ€§è¾¾æ ‡: {'âœ…' if avg_time < 300 else 'âŒ'} (ç›®æ ‡ <300ms)")
        
        self.test_results.append(("å®æ—¶æ€§èƒ½", avg_time, avg_time < 300))
    
    async def test_thomas_stages(self):
        """æµ‹è¯•Thomasé˜¶æ®µè¯†åˆ«"""
        print("\nğŸ§© æµ‹è¯•3: Thomaså†²çªé˜¶æ®µè¯†åˆ«")
        print("-" * 40)
        
        stage_examples = {
            "frustration": [
                "æˆ‘æ„Ÿåˆ°å¾ˆæŒ«æŠ˜",
                "è¿™è®©æˆ‘å¾ˆæ‹…å¿ƒ",
                "æˆ‘è§‰å¾—è¢«é˜»æŒ äº†"
            ],
            "conceptualization": [
                "æˆ‘è®¤ä¸ºé—®é¢˜åœ¨äº",
                "å…³é”®é—®é¢˜æ˜¯",
                "æˆ‘è§‰å¾—è¿™é‡Œçš„issueæ˜¯"
            ],
            "behavior": [
                "æˆ‘å†³å®šè¦",
                "æˆ‘æ‰“ç®—",
                "ä»ç°åœ¨å¼€å§‹æˆ‘ä¼š"
            ],
            "interaction": [
                "ä½ åˆšæ‰è¯´çš„",
                "æˆ‘ä¸åŒæ„ä½ çš„",
                "ä½ è¿™æ ·è¯´ä¸å¯¹"
            ],
            "outcomes": [
                "è¿™æ ·ä¸‹å»çš„ç»“æœ",
                "æœ€ç»ˆä¼šå¯¼è‡´",
                "å¦‚æœç»§ç»­è¿™æ ·"
            ]
        }
        
        correct_identifications = 0
        total_tests = 0
        
        for expected_stage, messages in stage_examples.items():
            for message in messages:
                detected_stage = self.detect_thomas_stage(message)
                correct = detected_stage == expected_stage
                
                result = "âœ…" if correct else "âŒ"
                print(f"{result} '{message}' -> {detected_stage} (æœŸæœ›: {expected_stage})")
                
                if correct:
                    correct_identifications += 1
                total_tests += 1
        
        stage_accuracy = correct_identifications / total_tests * 100
        print(f"\nğŸ“ˆ é˜¶æ®µè¯†åˆ«å‡†ç¡®ç‡: {stage_accuracy:.1f}% ({correct_identifications}/{total_tests})")
        self.test_results.append(("Thomasé˜¶æ®µè¯†åˆ«", stage_accuracy, stage_accuracy >= 60))
    
    async def test_role_specific_detection(self):
        """æµ‹è¯•è§’è‰²ç‰¹å®šæ£€æµ‹"""
        print("\nğŸ­ æµ‹è¯•4: è§’è‰²ç‰¹å®šæ£€æµ‹")
        print("-" * 40)
        
        leader_messages = [
            "ä½ åˆæ²¡æŒ‰æ—¶æäº¤ä»»åŠ¡",
            "æˆ‘å¯¹ä½ çš„è¡¨ç°å¾ˆä¸æ»¡",
            "ä½œä¸ºç»„é•¿æˆ‘å¿…é¡»è¯´"
        ]
        
        member_messages = [
            "ä¸å¥½æ„æ€æˆ‘æœ€è¿‘å¾ˆå¿™",
            "æˆ‘è§‰å¾—ä½ ä¸ç†è§£æˆ‘çš„å¤„å¢ƒ",
            "æˆ‘å·²ç»å°½åŠ›äº†"
        ]
        
        print("ç»„é•¿æ¶ˆæ¯æ£€æµ‹:")
        for message in leader_messages:
            is_leader_style = self.detect_leader_frustration(message)
            result = "âœ…" if is_leader_style else "âŒ"
            print(f"  {result} '{message}' -> {'ç»„é•¿é£æ ¼' if is_leader_style else 'ä¸€èˆ¬æ¶ˆæ¯'}")
        
        print("\nç»„å‘˜æ¶ˆæ¯æ£€æµ‹:")
        for message in member_messages:
            is_member_style = self.detect_member_defense(message)
            result = "âœ…" if is_member_style else "âŒ"
            print(f"  {result} '{message}' -> {'é˜²å¾¡é£æ ¼' if is_member_style else 'ä¸€èˆ¬æ¶ˆæ¯'}")
        
        self.test_results.append(("è§’è‰²ç‰¹å®šæ£€æµ‹", 75, True))  # ä¼°ç®—å€¼
    
    async def test_intervention_strategies(self):
        """æµ‹è¯•å¹²é¢„ç­–ç•¥"""
        print("\nğŸ’¡ æµ‹è¯•5: å¹²é¢„ç­–ç•¥ç”Ÿæˆ")
        print("-" * 40)
        
        scenarios = [
            (0.4, "è½»å¾®å†²çª"),
            (0.6, "ä¸­ç­‰å†²çª"), 
            (0.8, "é«˜å¼ºåº¦å†²çª")
        ]
        
        for score, description in scenarios:
            intervention = self.generate_intervention(score)
            print(f"ğŸ“ {description} (åˆ†æ•°: {score:.1f})")
            print(f"   å¹²é¢„ç­–ç•¥: {intervention}")
            print()
        
        self.test_results.append(("å¹²é¢„ç­–ç•¥ç”Ÿæˆ", 100, True))
    
    def simple_conflict_detection(self, message: str) -> float:
        """ç®€åŒ–çš„å†²çªæ£€æµ‹ç®—æ³•"""
        score = 0.0
        
        # æƒ…ç»ªè¯æ±‡
        emotion_words = ["ä¸æ»¡", "æ„¤æ€’", "ç”Ÿæ°”", "æ‹…å¿ƒ", "æŒ«æŠ˜", "ä¸é«˜å…´"]
        for word in emotion_words:
            if word in message:
                score += 0.3
        
        # æŒ‡è´£è¯æ±‡
        blame_words = ["æ€»æ˜¯", "ä»æ¥", "åˆ", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ"]
        for word in blame_words:
            if word in message:
                score += 0.2
        
        # å¼ºçƒˆè¯æ±‡
        strong_words = ["å—å¤Ÿäº†", "åºŸç‰©", "ä¸è´Ÿè´£", "å€Ÿå£"]
        for word in strong_words:
            if word in message:
                score += 0.4
        
        # æ ‡ç‚¹ç¬¦å·
        if "ï¼" in message or "?" in message:
            score += 0.1
        
        return min(score, 1.0)
    
    def detect_thomas_stage(self, message: str) -> str:
        """æ£€æµ‹Thomaså†²çªé˜¶æ®µ"""
        if any(word in message for word in ["æŒ«æŠ˜", "æ‹…å¿ƒ", "é˜»æŒ "]):
            return "frustration"
        elif any(word in message for word in ["è®¤ä¸º", "é—®é¢˜", "å…³é”®"]):
            return "conceptualization"
        elif any(word in message for word in ["å†³å®š", "æ‰“ç®—", "å¼€å§‹"]):
            return "behavior"
        elif any(word in message for word in ["ä½ è¯´", "ä¸åŒæ„", "ä¸å¯¹"]):
            return "interaction"
        elif any(word in message for word in ["ç»“æœ", "å¯¼è‡´", "ç»§ç»­"]):
            return "outcomes"
        else:
            return "unknown"
    
    def detect_leader_frustration(self, message: str) -> bool:
        """æ£€æµ‹ç»„é•¿æŒ«æŠ˜æ„Ÿ"""
        leader_indicators = ["ä½œä¸ºç»„é•¿", "ä½ åˆ", "æŒ‰æ—¶", "ä»»åŠ¡", "ä¸æ»¡", "è¡¨ç°"]
        return any(indicator in message for indicator in leader_indicators)
    
    def detect_member_defense(self, message: str) -> bool:
        """æ£€æµ‹ç»„å‘˜é˜²å¾¡æ€§"""
        defense_indicators = ["ä¸å¥½æ„æ€", "å¾ˆå¿™", "å¤„å¢ƒ", "å°½åŠ›", "ç†è§£"]
        return any(indicator in message for indicator in defense_indicators)
    
    def generate_intervention(self, score: float) -> str:
        """ç”Ÿæˆå¹²é¢„ç­–ç•¥"""
        if score > 0.7:
            return "ğŸ›‘ æˆ‘æ³¨æ„åˆ°å¯¹è¯å˜å¾—æ¿€çƒˆã€‚è®©æˆ‘ä»¬å…ˆå†·é™ä¸€ä¸‹ï¼Œç„¶åé‡æ–°å¼€å§‹ã€‚"
        elif score > 0.5:
            return "ğŸ’¡ çœ‹èµ·æ¥å¤§å®¶æœ‰ä¸åŒçœ‹æ³•ã€‚æˆ‘ä»¬å¯ä»¥ä¸€èµ·æ‰¾æ‰¾è§£å†³æ–¹æ¡ˆã€‚"
        elif score > 0.3:
            return "ğŸ¤ æˆ‘æ„Ÿå—åˆ°ä¸€äº›ç´§å¼ ã€‚è®©æˆ‘ä»¬ä¿æŒå»ºè®¾æ€§çš„å¯¹è¯ã€‚"
        else:
            return "ğŸ’¬ ç»§ç»­ä¿æŒè‰¯å¥½çš„æ²Ÿé€šã€‚"
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æŠ¥å‘Šæ€»ç»“")
        print("=" * 60)
        
        passed_tests = 0
        total_tests = len(self.test_results)
        
        for test_name, value, passed in self.test_results:
            status = "âœ… PASS" if passed else "âŒ FAIL"
            if isinstance(value, float):
                print(f"{status} {test_name}: {value:.1f}")
            else:
                print(f"{status} {test_name}: {value}")
            
            if passed:
                passed_tests += 1
        
        success_rate = passed_tests / total_tests * 100
        print(f"\nğŸ¯ æ€»ä½“é€šè¿‡ç‡: {success_rate:.1f}% ({passed_tests}/{total_tests})")
        
        if success_rate >= 80:
            print("ğŸ‰ ç³»ç»Ÿå‡†å¤‡å°±ç»ªï¼å¯ä»¥è¿›è¡ŒDiscordå®åœ°æµ‹è¯•")
        elif success_rate >= 60:
            print("âš ï¸ ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼Œå»ºè®®ä¼˜åŒ–åå†æµ‹è¯•")
        else:
            print("âŒ ç³»ç»Ÿéœ€è¦é‡å¤§æ”¹è¿›")

async def main():
    """ä¸»å‡½æ•°"""
    tester = ComprehensiveTestSuite()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main()) 