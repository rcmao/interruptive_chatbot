Proposal
1. Introduction
Group communication on platforms such as WeChat and Discord has become a central component of remote learning, collaborative decision-making, and public discourse. However, in practice, these multi-party conversations are often characterized by tension and poorly coordinated viewpoints, where task-related disagreements frequently escalate into emotionally charged confrontations. Such dynamics threaten not only the psychological safety of participants but also the quality and efficiency of group collaboration.
This problem is particularly pronounced in informal group chats lacking a human facilitator. In these settings, dominant participants may suppress dissenting voices, while less vocal members may experience alienation due to the lack of space for meaningful contribution. As a result, the imbalance in conversational dynamics can significantly diminish deliberation quality and decision-making effectiveness.
Prior work has demonstrated that this issue has serious implications for psychological safety (Edmondson, 1999), collaborative efficiency, and diversity of perspectives (Jehn, 1995). More recently, Lee et al. (2023) highlight the promise of structured AI participation in supporting weaker voices and fostering inclusive conversational climates. Consequently, a key research challenge emerges: How can we design automated and structural mechanisms that support rational dialogue and conflict mitigation in group conversations without human moderation? (Govers et al., 2024).
Timely and well-crafted interruptions can play a critical role in preventing emotional escalation and facilitating reasoned deliberation. Research shows that early interventions during conflict can help sustain constructive dialogue and reduce the likelihood of task conflict turning into relational conflict (Jehn, 1995). Goldberg (1990) further emphasizes that neutral interruptions can reorient group focus toward shared goals, limiting emotional derailment and misalignment. Thomas’s process model of conflict (1992) identifies five phases—Frustration, Conceptualization, Intent, Behavior, and Outcomes—and points to the Frustration–Intent phase as the ideal window for intervention before escalation becomes irreversible.
Recent studies have demonstrated the potential of AI in online conflict mediation. Wu et al. (2024) found that GPT-4 can effectively identify when to intervene in emotionally charged exchanges and generate persuasive interventions that outperform novice human mediators. Govers et al. (2024) further showed that AI intervention styles informed by the TKI conflict model can reduce ideological polarization. However, most of these studies focus on dyadic and post-hoc interventions, leaving open questions about how to scale real-time, early-stage intervention mechanisms to multi-party group conversations.
Despite these promising findings, little is known about how AI can proactively identify opportune interruption moments in multi-party, task-oriented group dialogues, or how different intervention styles affect users’ perceptions, emotional dynamics, and collaboration outcomes. This research proposes an AI-based system that detects conflict escalation in real time and uses neutral and structured interruption strategies to explore the impact of AI-mediated interventions on user experience, group coordination, and decision-making quality.

2. Research Questions
RQ1: How can AI effectively detect appropriate moments to interrupt during conflict in multi-party group conversations?


RQ2: How do users perceive AI interventions in collaborative group settings, particularly those using neutral and structured language?



3. Literature Review
3.1 Challenges in Group Conflict Mediation
 Understanding task vs. relational conflict, escalation dynamics, and the limitations of human moderation in informal settings.
3.2 AI in Conflict Mediation
 Exploring the emerging potential of LLMs in dispute resolution, emotional regulation, and dialogic reframing.
3.3 AI-Based Interruption Mechanisms
 Reviewing existing models for AI turn-taking, interruption timing, and linguistic strategies for group alignment and trust.

4. Methodology
This study investigates how an AI chatbot can regulate multi-party group conflict by interrupting conversations during the Frustration–Intent phase of the conflict process. We evaluate the effect of such interventions on decision quality, collaboration efficiency, and psychological safety through a controlled lab study and user-centered evaluations.

4.1 Experimental Design
4.1.1 Conflict Scenario Design
Participants will engage in group decision-making tasks (e.g., resource allocation, prioritization) designed to naturally elicit both task and relational conflict. AI will monitor conversations and intervene during the Frustration–Intent phase, when emotional tension begins rising but before it manifests as overt confrontation.
According to Thomas’s (1992) model, the ideal intervention point lies between Intent formation and Behavioral expression. The AI will be trained to detect emotional escalation and issue interventions to prevent further conflict development.
4.1.2 AI Intervention Mechanism
The AI will use neutral and structured interruption strategies based on two capabilities:
Timing Detection: Leveraging emotion analysis and task divergence metrics to identify the Frustration–Intent window.


Message Generation: Producing non-intrusive, goal-oriented prompts that guide the group back to rational discussion without asserting authority.



5. Procedure
5.1 Task Assignment and Conflict Simulation
Participants will be assigned collaborative decision tasks likely to spark conflicting opinions. Scenarios will be designed to generate both task-related disagreements and emotionally sensitive dynamics.
5.2 AI Intervention Protocol
During the discussion, the AI will continuously analyze dialogue patterns. Upon detecting signals of rising frustration and potential intent escalation, it will issue structured prompts such as:
Refocusing questions (e.g., “Can we revisit our main objective?”)


Clarifying misunderstandings


Reminding the group of shared goals and mutual respect


5.3 Evaluation and Feedback
After completing the task, participants will fill out structured questionnaires and provide open-ended feedback. Key evaluation dimensions include:
Task Completion: Was a decision reached, and how well-reasoned was it?


Collaboration Efficiency: Duration of discussion and overall conversational smoothness.


Psychological Safety: Assessed via Edmondson’s (1999) scale, focusing on comfort in expressing dissent and minority opinions.



6. Data Collection & Analysis
6.1 Quantitative Measures
Task Performance: Measured by consensus quality and decision robustness.


Efficiency: Conversation length, turn-taking balance, and resolution time.


Psychological Safety: Using validated scales to assess perceived safety in participation.


6.2 Qualitative Measures
Discourse Analysis: Comparing emotional tone, focus shifts, and rationality before and after AI interruptions.


Participant Feedback: Thematic analysis of users’ perceptions regarding the AI’s usefulness, timing, and intrusiveness.



7. Hypotheses & Expected Outcomes
H1: AI-mediated interruptions will reduce emotional escalation and promote rational dialogue.


H2: Neutral and structured AI interventions will improve group decision quality and coordination efficiency, especially in task conflict scenarios.


We anticipate that the proposed AI system will demonstrate the viability of proactive, non-authoritative interventions in enhancing collaboration, reducing conflict, and supporting inclusive group communication.
